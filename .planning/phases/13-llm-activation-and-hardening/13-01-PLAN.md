---
phase: 13-llm-activation-and-hardening
plan: 01
type: execute
wave: 1
depends_on: []
requirements:
  - LLM-09
  - LLM-10
  - LLM-13
files_modified:
  - backend/app/agent/llm_helpers.py
  - backend/app/core/llm_config.py
  - backend/tests/test_llm_helpers.py
autonomous: true

must_haves:
  truths:
    - "_strip_json_fences removes ```json...``` and ```...``` wrappers from LLM output"
    - "_parse_json_response calls _strip_json_fences then json.loads"
    - "_invoke_with_retry retries only on OverloadedError, not on other exceptions"
    - "_invoke_with_retry stops after 4 attempts (1 original + 3 retries)"
    - "_invoke_with_retry logs at WARNING level before each retry sleep"
    - "UsageTrackingCallback.on_llm_end logs DB write failures at WARNING level instead of silently swallowing"
    - "UsageTrackingCallback.on_llm_end logs Redis write failures at WARNING level instead of silently swallowing"
  artifacts:
    - path: "backend/app/agent/llm_helpers.py"
      provides: "Shared LLM utility functions for retry, fence-stripping, JSON parsing"
      contains: "_strip_json_fences"
    - path: "backend/app/agent/llm_helpers.py"
      provides: "Tenacity retry decorator for OverloadedError"
      contains: "OverloadedError"
    - path: "backend/app/core/llm_config.py"
      provides: "Fixed UsageTrackingCallback with WARNING logging"
      contains: "logger.warning"
    - path: "backend/tests/test_llm_helpers.py"
      provides: "Unit tests for fence stripping and JSON parsing"
  key_links:
    - from: "backend/app/agent/llm_helpers.py"
      to: "anthropic._exceptions.OverloadedError"
      via: "import for retry_if_exception_type"
      pattern: "from anthropic._exceptions import OverloadedError"
    - from: "backend/app/agent/llm_helpers.py"
      to: "tenacity"
      via: "retry decorator"
      pattern: "from tenacity import"
---

<objective>
Create shared LLM helper utilities (retry, fence-stripping, JSON parsing) and fix UsageTrackingCallback silent failures.

Purpose: All RunnerReal methods need retry on Claude 529 overload, markdown fence stripping before JSON parsing, and the callback must log failures instead of silently swallowing them. This plan establishes the foundation that every subsequent plan depends on.

Output: New `llm_helpers.py` module with 3 utility functions, fixed `UsageTrackingCallback` with WARNING logging, and unit tests.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/13-llm-activation-and-hardening/13-CONTEXT.md
@.planning/phases/13-llm-activation-and-hardening/13-RESEARCH.md

@backend/app/core/llm_config.py
@backend/app/agent/runner_real.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create llm_helpers.py with retry, fence-stripping, and JSON parsing</name>
  <files>
    backend/app/agent/llm_helpers.py
    backend/tests/test_llm_helpers.py
  </files>
  <action>
**Create `backend/app/agent/llm_helpers.py`** with the following functions:

1. **`_strip_json_fences(content: str) -> str`** — Remove markdown code fences from LLM output:
   - Strip leading/trailing whitespace
   - If content starts with ` ```json ` or ` ``` `, remove the opening fence line and the closing ` ``` `
   - Handle both ` ```json\n ` and ` ```\n ` variants
   - Return cleaned content

```python
import json
import logging
import re

from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)
from anthropic._exceptions import OverloadedError

logger = logging.getLogger(__name__)


def _strip_json_fences(content: str) -> str:
    """Remove markdown code fences wrapping JSON output."""
    content = content.strip()
    if content.startswith("```"):
        first_newline = content.find("\n")
        if first_newline != -1:
            content = content[first_newline + 1:]
        if content.endswith("```"):
            content = content[:-3].rstrip()
    return content


def _parse_json_response(content: str) -> dict | list:
    """Parse JSON from LLM response, stripping fences first."""
    return json.loads(_strip_json_fences(content))


@retry(
    retry=retry_if_exception_type(OverloadedError),
    stop=stop_after_attempt(4),
    wait=wait_exponential(multiplier=2, min=2, max=30),
    reraise=True,
    before_sleep=lambda rs: logger.warning(
        "Claude overloaded (attempt %d/4), retrying in %.1fs",
        rs.attempt_number,
        rs.next_action.sleep,
    ),
)
async def _invoke_with_retry(llm, messages):
    """Invoke LLM with retry on Claude 529 overload.

    Retries up to 3 times with exponential backoff (2s, 4s, 8s max 30s).
    Only retries OverloadedError (529). All other exceptions propagate immediately.
    """
    return await llm.ainvoke(messages)
```

2. **Create `backend/tests/test_llm_helpers.py`** with unit tests:

```python
"""Tests for LLM helper utilities."""
import json
import pytest
from unittest.mock import AsyncMock, MagicMock

from app.agent.llm_helpers import _strip_json_fences, _parse_json_response


class TestStripJsonFences:
    def test_no_fences(self):
        raw = '{"key": "value"}'
        assert _strip_json_fences(raw) == '{"key": "value"}'

    def test_json_fence(self):
        raw = '```json\n{"key": "value"}\n```'
        assert _strip_json_fences(raw) == '{"key": "value"}'

    def test_plain_fence(self):
        raw = '```\n{"key": "value"}\n```'
        assert _strip_json_fences(raw) == '{"key": "value"}'

    def test_fence_with_whitespace(self):
        raw = '  ```json\n{"key": "value"}\n```  '
        assert _strip_json_fences(raw) == '{"key": "value"}'

    def test_array_fence(self):
        raw = '```json\n[{"id": 1}]\n```'
        assert _strip_json_fences(raw) == '[{"id": 1}]'

    def test_nested_content_preserved(self):
        raw = '```json\n{"code": "```python\\nprint()\\n```"}\n```'
        # Only strips outermost fences
        result = _strip_json_fences(raw)
        assert result.startswith('{"code":')


class TestParseJsonResponse:
    def test_plain_json(self):
        result = _parse_json_response('{"key": "value"}')
        assert result == {"key": "value"}

    def test_fenced_json(self):
        result = _parse_json_response('```json\n{"key": "value"}\n```')
        assert result == {"key": "value"}

    def test_array_json(self):
        result = _parse_json_response('[{"id": 1}, {"id": 2}]')
        assert result == [{"id": 1}, {"id": 2}]

    def test_invalid_json_raises(self):
        with pytest.raises(json.JSONDecodeError):
            _parse_json_response("not json at all")
```
  </action>
  <verify>
Run `cd /Users/vladcortex/co-founder/backend && python -c "from app.agent.llm_helpers import _strip_json_fences, _parse_json_response, _invoke_with_retry; print('Imports OK')"` — verify all 3 functions import.
Run `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/test_llm_helpers.py -v` — all tests pass.
  </verify>
  <done>
llm_helpers.py provides _strip_json_fences, _parse_json_response, and _invoke_with_retry. All functions are importable. Unit tests pass for fence stripping and JSON parsing edge cases.
  </done>
</task>

<task type="auto">
  <name>Task 2: Fix UsageTrackingCallback silent exception swallowing</name>
  <files>
    backend/app/core/llm_config.py
  </files>
  <action>
In `backend/app/core/llm_config.py`, make two changes:

1. **Add logger at module level** (after imports, before MODEL_COSTS):
```python
import logging

logger = logging.getLogger(__name__)
```

2. **Replace bare `except: pass` blocks in `on_llm_end`** (lines 188-189 and 198-199):

Change the Postgres write exception handler (line 188-189):
```python
        except Exception:
            pass  # Usage logging should never block agent execution
```
to:
```python
        except Exception as e:
            logger.warning("UsageTrackingCallback: DB write failed (non-blocking): %s", e)
```

Change the Redis write exception handler (line 198-199):
```python
        except Exception:
            pass
```
to:
```python
        except Exception as e:
            logger.warning("UsageTrackingCallback: Redis write failed (non-blocking): %s", e)
```

The logging import may already exist — check first. If not, add `import logging` to the imports section and `logger = logging.getLogger(__name__)` at module level.
  </action>
  <verify>
Run `cd /Users/vladcortex/co-founder/backend && python -c "from app.core.llm_config import UsageTrackingCallback; print('Import OK')"` — no import errors.
Grep for `except:` in llm_config.py — should return zero results (no bare excepts remain).
Grep for `logger.warning.*UsageTrackingCallback` in llm_config.py — should find 2 results.
  </verify>
  <done>
UsageTrackingCallback.on_llm_end now logs DB and Redis write failures at WARNING level with the exception message. No silent `except: pass` blocks remain. Founders never see these errors; operators see them in server logs.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from app.agent.llm_helpers import _strip_json_fences, _parse_json_response, _invoke_with_retry"` succeeds
2. `python -m pytest tests/test_llm_helpers.py -v` — all tests pass
3. No bare `except: pass` in llm_config.py
4. Two `logger.warning` calls in UsageTrackingCallback.on_llm_end
</verification>

<success_criteria>
- _strip_json_fences correctly removes ```json...``` and ```...``` wrappers
- _parse_json_response chains fence stripping with json.loads
- _invoke_with_retry retries only OverloadedError with exponential backoff, stops after 4 attempts, logs retries at WARNING
- UsageTrackingCallback logs DB/Redis failures at WARNING, never swallows silently
- Unit tests cover fence stripping edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/13-llm-activation-and-hardening/13-01-SUMMARY.md`
</output>
