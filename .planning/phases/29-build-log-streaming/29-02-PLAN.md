---
phase: 29-build-log-streaming
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/api/routes/logs.py
  - backend/tests/api/test_logs_api.py
  - backend/app/api/routes/__init__.py
autonomous: true
requirements:
  - BUILD-01

must_haves:
  truths:
    - "GET /api/jobs/{id}/logs/stream delivers log lines as SSE events to an authenticated client"
    - "SSE stream sends heartbeat events every 20 seconds to prevent ALB idle timeout"
    - "SSE stream sends a 'done' event and closes when job reaches READY or FAILED"
    - "GET /api/jobs/{id}/logs returns paginated log lines from Redis Stream for 'Load earlier' feature"
    - "Both endpoints require Clerk JWT auth and verify job ownership (404 for non-owner)"
    - "Late joiners see live lines only (last_id='$') — no full replay on initial SSE connect"
  artifacts:
    - path: "backend/app/api/routes/logs.py"
      provides: "SSE streaming endpoint and REST pagination endpoint"
      min_lines: 80
    - path: "backend/tests/api/test_logs_api.py"
      provides: "Tests for auth, ownership, SSE events, pagination"
      min_lines: 60
  key_links:
    - from: "backend/app/api/routes/logs.py"
      to: "backend/app/core/auth.py"
      via: "Depends(require_auth)"
      pattern: "require_auth"
    - from: "backend/app/api/routes/logs.py"
      to: "redis.asyncio xread/xrevrange"
      via: "redis.xread() polling and redis.xrevrange() for pagination"
      pattern: "xread|xrevrange"
    - from: "backend/app/api/routes/__init__.py"
      to: "backend/app/api/routes/logs.py"
      via: "api_router.include_router(logs.router)"
      pattern: "logs\\.router"
---

<objective>
Create the SSE streaming endpoint (`GET /api/jobs/{id}/logs/stream`) and REST pagination endpoint (`GET /api/jobs/{id}/logs`) for build log delivery, plus register the router.

Purpose: These endpoints expose the Redis Stream data written by LogStreamer (Plan 01) to frontend clients. The SSE endpoint delivers live build output; the REST endpoint enables "Load earlier" history access. Both require Clerk JWT auth with job ownership verification.

Output: `backend/app/api/routes/logs.py` with both endpoints, `backend/tests/api/test_logs_api.py` with tests, updated `__init__.py` with router registration.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-build-log-streaming/29-RESEARCH.md
@backend/app/api/routes/jobs.py
@backend/app/core/auth.py
@backend/app/db/redis.py
@backend/app/queue/state_machine.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SSE and REST log endpoints with router registration</name>
  <files>backend/app/api/routes/logs.py, backend/app/api/routes/__init__.py</files>
  <action>
    Create `backend/app/api/routes/logs.py` with two endpoints following the existing SSE pattern in `jobs.py`:

    **Endpoint 1: `GET /{job_id}/logs/stream` — SSE streaming**
    - Dependencies: `user: ClerkUser = Depends(require_auth)`, `redis = Depends(get_redis)`, `request: Request`
    - Auth + ownership check: Load job via `JobStateMachine.get_job(job_id)`, return 404 if not found or `user_id != user.user_id`
    - Return `StreamingResponse(event_generator(), media_type="text/event-stream")` with headers: `Cache-Control: no-cache`, `Connection: keep-alive`, `X-Accel-Buffering: no`
    - `event_generator()` async generator:
      - Set `last_id = "$"` (live-only — per locked decision, no full replay on initial connect)
      - Loop with 500ms `xread` block polling on stream key `job:{job_id}:logs`
      - On each iteration: check heartbeat timer (20s interval), emit `event: heartbeat\ndata: {}\n\n` if due
      - On each iteration: check `await request.is_disconnected()` — if True, return (clean exit)
      - Check job terminal state via `state_machine.get_status(job_id)` — if `ready` or `failed`:
        - Drain remaining entries with `xread` (no block, count=200)
        - Yield all as `event: log\ndata: {...}\n\n`
        - Yield `event: done\ndata: {"status": "ready|failed"}\n\n`
        - Return (close connection)
      - For non-terminal: yield entries as `event: log\ndata: {"ts": ..., "source": ..., "text": ..., "phase": ...}\n\n`
      - Wrap xread in try/except — on error, asyncio.sleep(0.5) and continue

    **Endpoint 2: `GET /{job_id}/logs` — REST pagination ("Load earlier")**
    - Dependencies: same auth pattern
    - Query params: `before_id: str | None = Query(None)`, `limit: int = Query(100, ge=1, le=500)`
    - Auth + ownership check: same as above
    - Use `redis.xrevrange(stream_key, max=before_id or "+", count=limit + 1)` to read in reverse
    - Determine `has_more = len(raw) > limit`, take first `limit` entries, reverse to chronological order
    - Return JSON: `{"lines": [{"id": ..., "ts": ..., "source": ..., "text": ..., "phase": ...}], "has_more": bool, "oldest_id": str | None}`

    **Router registration in `__init__.py`:**
    - Add `from app.api.routes import logs` to imports
    - Add `api_router.include_router(logs.router, prefix="/jobs", tags=["logs"])` — mount under `/jobs` prefix so endpoints become `/api/jobs/{id}/logs/stream` and `/api/jobs/{id}/logs`
  </action>
  <verify>
    ```bash
    cd /Users/vladcortex/co-founder/backend && python -c "from app.api.routes.logs import router; print(f'Routes: {[r.path for r in router.routes]}')"
    ```
    Prints routes including `/{job_id}/logs/stream` and `/{job_id}/logs`.
  </verify>
  <done>Both endpoints importable. Router registered in __init__.py. SSE uses live-only last_id="$", 20s heartbeat, request.is_disconnected() check. REST uses xrevrange with pagination.</done>
</task>

<task type="auto">
  <name>Task 2: Test SSE and REST log endpoints</name>
  <files>backend/tests/api/test_logs_api.py</files>
  <action>
    Create `backend/tests/api/test_logs_api.py` with tests using fakeredis. Follow the test patterns from `tests/api/test_jobs_api.py` (mock auth, use fakeredis for Redis):

    **Setup:** Use fakeredis.aioredis.FakeRedis(). Create job in Redis via JobStateMachine.create_job(). Seed log entries via redis.xadd() directly.

    **Tests for REST endpoint (GET /{job_id}/logs):**
    1. `test_get_logs_returns_entries` — Seed 3 entries in stream, GET /api/jobs/{id}/logs → 200, body has 3 lines in chronological order, has_more=False
    2. `test_get_logs_pagination` — Seed 5 entries, request with limit=2 → 2 lines + has_more=True + oldest_id set
    3. `test_get_logs_auth_required` — No auth header → 401
    4. `test_get_logs_wrong_user` — Auth as different user → 404
    5. `test_get_logs_empty_stream` — No entries → 200, lines=[], has_more=False

    **Tests for SSE endpoint (GET /{job_id}/logs/stream):**
    6. `test_stream_logs_auth_required` — No auth → 401
    7. `test_stream_logs_wrong_user` — Different user → 404

    Note: Full SSE streaming tests (consuming the async generator with live xread polling) are harder to test with httpx TestClient because streaming responses are consumed differently. For unit-level confidence, test the auth/ownership gates and the REST endpoint. The SSE generator logic is validated by the integration of Plan 01 + Plan 03.

    Use the same auth mocking pattern as `tests/api/test_jobs_api.py` (patch `require_auth` dependency override).
  </action>
  <verify>
    ```bash
    cd /Users/vladcortex/co-founder/backend && python -m pytest tests/api/test_logs_api.py -v
    ```
    All tests pass.
  </verify>
  <done>7+ tests covering REST pagination, auth gates, ownership checks for both endpoints. All pass with fakeredis.</done>
</task>

</tasks>

<verification>
```bash
cd /Users/vladcortex/co-founder/backend && python -m pytest tests/api/test_logs_api.py -v
```
All tests pass. Router registered and importable.
</verification>

<success_criteria>
- GET /api/jobs/{id}/logs/stream returns StreamingResponse with SSE events (log, heartbeat, done)
- GET /api/jobs/{id}/logs returns paginated JSON with lines, has_more, oldest_id
- Both endpoints require Clerk JWT auth and verify job ownership
- Router registered in __init__.py under /jobs prefix
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/29-build-log-streaming/29-02-SUMMARY.md`
</output>
