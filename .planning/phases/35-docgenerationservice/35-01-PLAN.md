---
phase: 35-docgenerationservice
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - backend/app/services/doc_generation_service.py
  - backend/tests/services/test_doc_generation_service.py
autonomous: true
requirements: [DOCS-01, DOCS-02, DOCS-07, DOCS-08]

must_haves:
  truths:
    - "DocGenerationService.generate() calls Anthropic Haiku model with structured JSON prompt and writes four sections to Redis hash"
    - "Sections are written progressively (overview first, then features, getting_started, faq) with an SSE event emitted per section"
    - "Content safety filter strips code fences, inline code, CLI commands, Unix paths, filenames, and framework names from all sections before Redis write"
    - "generate() never raises — RateLimitError, TimeoutError, JSONDecodeError, and any other exception are caught internally and _status set to failed/partial"
    - "One retry with ~2.5s backoff on API failure; second failure marks _status as failed"
  artifacts:
    - path: "backend/app/services/doc_generation_service.py"
      provides: "DocGenerationService class with generate(), _call_claude_with_retry(), _parse_sections(), _write_sections(), _apply_safety_filter(), _build_prompt()"
      min_lines: 120
    - path: "backend/tests/services/test_doc_generation_service.py"
      provides: "Unit tests covering all behavior paths"
      min_lines: 200
  key_links:
    - from: "backend/app/services/doc_generation_service.py"
      to: "anthropic.AsyncAnthropic"
      via: "messages.create() with model claude-3-5-haiku-20241022"
      pattern: "AsyncAnthropic.*messages\\.create"
    - from: "backend/app/services/doc_generation_service.py"
      to: "job:{job_id}:docs Redis hash"
      via: "redis.hset() per section"
      pattern: "hset.*job:.*:docs"
    - from: "backend/app/services/doc_generation_service.py"
      to: "app.queue.state_machine.JobStateMachine.publish_event()"
      via: "SSEEventType.DOCUMENTATION_UPDATED per section"
      pattern: "DOCUMENTATION_UPDATED"
---

<objective>
Build DocGenerationService as a self-contained async class that calls the Anthropic Haiku API, parses a structured JSON response into four documentation sections, applies a content safety filter, writes each section progressively to a Redis hash, and emits SSE events per section — all with comprehensive error handling that never raises to the caller.

Purpose: Founders see personalized product documentation appearing during their build, written in end-user-facing language. The service must be completely isolated from the build critical path — any failure results in a warning log, never a build failure.

Output: `doc_generation_service.py` with DocGenerationService class + `test_doc_generation_service.py` with full unit test suite.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/35-docgenerationservice/35-RESEARCH.md
@.planning/phases/35-docgenerationservice/35-CONTEXT.md

# Reference patterns (read these for structural alignment):
@backend/app/services/screenshot_service.py
@backend/tests/services/test_screenshot_service.py
@backend/app/queue/state_machine.py  # SSEEventType.DOCUMENTATION_UPDATED, publish_event()
@backend/app/agent/llm_helpers.py    # _strip_json_fences() for reuse
@backend/app/core/config.py          # get_settings().docs_generation_enabled, anthropic_api_key
</context>

<feature>
  <name>DocGenerationService — Claude-powered documentation generation</name>
  <files>backend/app/services/doc_generation_service.py, backend/tests/services/test_doc_generation_service.py</files>
  <behavior>
    The service has one public method: `generate(job_id, spec, redis)`. It never raises.

    **DOCS-01: Claude API call with Haiku model**
    - Call `anthropic.AsyncAnthropic(api_key=settings.anthropic_api_key).messages.create()` directly (NOT through LangChain/create_tracked_llm)
    - Model: `"claude-3-5-haiku-20241022"` (per user decision: "Use Haiku model")
    - max_tokens: 1500
    - Wrap in `asyncio.wait_for(timeout=30.0)` — DOC_GEN_TIMEOUT_SECONDS = 30.0
    - System prompt per CONTEXT.md decisions: warm co-founder tone, end-user audience, structured JSON output, positive and negative instructions, one-shot example
    - User message: summarized spec (the `goal` string — not raw verbatim, summarize to avoid parroting)
    - Request structured JSON response: `{overview, features, getting_started, faq}` — each value is markdown
    - Parse response through `_strip_json_fences()` from `app.agent.llm_helpers` before `json.loads()`

    Cases:
    - `generate(job_id, spec="Build a task manager app", redis)` -> writes 4 sections to Redis, _status = "complete"
    - `generate(job_id, spec="", redis)` -> still attempts generation (empty spec is valid, Claude infers)

    **DOCS-02: Progressive section writes with SSE events**
    - SECTION_ORDER = ["overview", "features", "getting_started", "faq"]
    - After parsing JSON, iterate sections in order
    - For each valid section: apply safety filter, then `redis.hset(f"job:{job_id}:docs", key, safe_content)`, then `state_machine.publish_event(job_id, {"type": SSEEventType.DOCUMENTATION_UPDATED, "section": key})`
    - Set `_status` key in hash: "pending" at start, "generating" after first hset, "complete" if all 4 written, "partial" if 1-3 written, "failed" if 0 written
    - Progressive means: overview appears in Redis first, then features, etc. Each write is followed by its SSE event before moving to next section

    Cases:
    - All 4 sections valid -> _status = "complete"
    - 2 valid, 2 malformed (non-string) -> _status = "partial", only valid 2 written
    - 0 valid sections in JSON -> _status = "failed"

    **DOCS-07: Content safety filter**
    - `_apply_safety_filter(content: str) -> str` applied to each section BEFORE Redis write
    - Strip code blocks (triple backtick fenced blocks)
    - Strip inline code (single backtick wrapped)
    - Strip shell prompts (lines starting with $ or > followed by command)
    - Strip Unix paths (/home/, /usr/, /var/, /tmp/, /app/, /src/ followed by non-whitespace)
    - Strip source filenames (PascalCase.py, PascalCase.ts, PascalCase.js, etc.)
    - Strip framework/library names using word boundaries: React, Next.js, FastAPI, PostgreSQL, Redis, Node.js, Django, Flask, Vue, Angular, TypeScript, Express, MongoDB, Prisma, Drizzle, SQLAlchemy
    - Return stripped + whitespace-normalized content
    - Keep regex patterns specific with word boundaries (\b) to avoid false positives (e.g., "reactive" should NOT be stripped)

    Cases:
    - "Built with ```npm install``` and React" -> "Built with  and "
    - "Check /home/user/project/src/App.tsx" -> "Check "
    - "Your app is reactive and fast" -> "Your app is reactive and fast" (not stripped)

    **DOCS-08: Non-fatal failure handling**
    - `generate()` wraps EVERYTHING in try/except Exception
    - One retry with ~2.5s backoff on RateLimitError, APITimeoutError, asyncio.TimeoutError
    - If second attempt fails: log warning, set _status = "failed", return None
    - If JSON parse fails: log warning, set _status = "failed", return None
    - If Redis write fails mid-way: log warning, _status stays as last successful state
    - Never raise any exception from generate() — it's called via asyncio.create_task()
    - All failures logged with structlog.warning (not error) including job_id

    Cases:
    - RateLimitError on first call -> retry after 2.5s -> success on second -> "complete"
    - RateLimitError on first call -> TimeoutError on second -> _status = "failed", returns None
    - json.JSONDecodeError on parse -> _status = "failed", returns None
    - Exception during redis.hset -> logged, generate() returns None
  </behavior>
  <implementation>
    Mirror ScreenshotService class structure from backend/app/services/screenshot_service.py:

    ```python
    # Constants
    SECTION_ORDER = ["overview", "features", "getting_started", "faq"]
    DOC_GEN_TIMEOUT_SECONDS = 30.0
    DOC_GEN_MODEL = "claude-3-5-haiku-20241022"
    DOC_GEN_MAX_TOKENS = 1500

    class DocGenerationService:
        async def generate(self, job_id: str, spec: str, redis) -> None:
            """Entry point. Called via asyncio.create_task(). Never raises."""

        async def _call_claude_with_retry(self, spec: str) -> dict:
            """One retry with 2.5s backoff. Raises on second failure."""

        def _build_prompt(self, spec: str) -> tuple[str, list[dict]]:
            """Build system prompt + messages list from spec."""

        def _parse_sections(self, raw_response: dict) -> dict:
            """Extract valid string sections from parsed JSON."""

        async def _write_sections(self, job_id: str, sections: dict, redis) -> None:
            """Write sections progressively to Redis with SSE events."""

        def _apply_safety_filter(self, content: str) -> str:
            """Regex-based content safety filter."""
    ```

    Key implementation details:
    - Create `anthropic.AsyncAnthropic(api_key=get_settings().anthropic_api_key)` per call (no persistent client state)
    - Use `_strip_json_fences()` from `app.agent.llm_helpers` before `json.loads()`
    - Use `JobStateMachine(redis).publish_event()` for SSE events
    - System prompt includes one-shot example (TaskFlow example from RESEARCH.md)
    - Both positive and negative instructions in system prompt per CONTEXT.md
    - `_apply_safety_filter` uses compiled regex patterns (module-level `re.compile()` for performance)
    - structlog for all logging
  </implementation>
</feature>

<verification>
```bash
# Run full test suite for doc generation service
pytest backend/tests/services/test_doc_generation_service.py -x -v

# Verify no import errors
python -c "from app.services.doc_generation_service import DocGenerationService; print('OK')"

# Verify test count (expect 15+ tests covering all behavior paths)
pytest backend/tests/services/test_doc_generation_service.py --collect-only -q | tail -1
```
</verification>

<success_criteria>
- DocGenerationService class exists with generate(), _call_claude_with_retry(), _build_prompt(), _parse_sections(), _write_sections(), _apply_safety_filter()
- All tests pass: API call structure, progressive writes, safety filter, failure paths
- generate() is verified to never raise (test catches and asserts no exception propagation)
- Safety filter correctly strips code fences, paths, framework names while preserving normal text
- Retry logic verified: first failure retries after sleep, second failure sets _status=failed
- Progressive write verified: sections appear in Redis in correct order with SSE event per section
</success_criteria>

<output>
After completion, create `.planning/phases/35-docgenerationservice/35-01-SUMMARY.md`
</output>
