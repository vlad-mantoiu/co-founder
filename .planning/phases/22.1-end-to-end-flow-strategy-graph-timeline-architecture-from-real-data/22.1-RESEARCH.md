# Phase 22.1: End-to-End Flow — Strategy Graph, Timeline & Architecture from Real Data - Research

**Researched:** 2026-02-21
**Domain:** LLM artifact generation pipeline, FastAPI background tasks, Next.js UI state machines, React Force Graph
**Confidence:** HIGH (all findings derived from direct codebase inspection)

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions

#### Strategy Graph content
- Full strategic plan: combines go-to-market roadmap AND business model map into a comprehensive strategy visualization
- User's own words appear as anchor nodes (verbatim from their answers) with LLM-derived strategy nodes connecting them
- Primary emotional response: "This AI gets my idea" — the graph proves the system understood the user by showing their exact words validated and organized into a real plan
- Interactivity level: Claude's discretion (based on what's already built)

#### Timeline & milestones
- Detailed MVP launch timeline as primary view, with a lighter long-term product roadmap section
- Relative durations (weeks), not calendar dates — user decides when to start
- Adapts both scope AND duration to the user's technical level and resources from Onboarding
- Each milestone lists 2-3 concrete deliverables — e.g., "Validation: 2 weeks — landing page, 50 signups, user interviews"

#### Architecture artifact
- Two layers: high-level component diagram (Frontend, Backend, Database, APIs) PLUS specific tech stack recommendations for each component
- Simplified by default for everyone, with expandable detail for curious/technical users
- Include rough cost estimates — "~$50/mo to start, ~$200/mo at 1k users" to help founders budget
- Integration recommendations: Claude's discretion based on idea complexity

#### Flow experience
- After Understanding completes: auto-generate immediately — no manual trigger, the magic just happens
- During generation: step-by-step progress — "Analyzing your idea... Building strategy... Creating timeline..." showing each artifact being generated
- After generation: guided walkthrough — step through each artifact one by one ("Here's your Strategy" → next → "Here's your Timeline" → next → "Here's your Architecture")
- Error handling: retry silently up to 3 times — user never sees the failure unless all retries fail

### Claude's Discretion
- Strategy Graph interactivity level (read-only vs light editing)
- Integration recommendations scope (based on idea complexity)
- Technical detail in expandable architecture sections

### Deferred Ideas (OUT OF SCOPE)
None — discussion stayed within phase scope
</user_constraints>

---

## Summary

The codebase already has substantial infrastructure in place, but Phase 22.1 requires wiring all of it together with new LLM generation logic. The current state: the Understanding Interview completes and produces a `RationalisedIdeaBrief` stored as an `Artifact` (type: `idea_brief`). After that, **nothing happens automatically** — the three personalized artifacts (Strategy Graph, Timeline, Architecture) are not generated from that brief.

The Strategy Graph (`/projects/:id/strategy`) displays Neo4j nodes but currently only receives nodes from `DecisionGate` and `StageEvent` syncs — it never receives nodes derived from the Onboarding/Understanding answers. The Timeline page (`/projects/:id/timeline`) shows aggregated events from PostgreSQL but these are system events, not a personalized MVP timeline. The Architecture page (`/projects/:id/architecture`) only shows agent session plan steps — not a personalized tech stack recommendation.

**The core work:** (1) Add three new `ArtifactType` values to the existing artifact pipeline, (2) Add three new `Runner` protocol methods for LLM generation, (3) Wire auto-generation after `finalize_interview`, (4) Build a generation progress overlay UI, (5) Replace stub pages with real artifact display components.

**Primary recommendation:** Extend the existing Runner/ArtifactService/Artifact pattern rather than creating parallel infrastructure. Use FastAPI `BackgroundTasks` (already used in `/api/generation/start`) for async generation. Keep the auto-trigger inside `understanding_service.finalize()` using the same pattern as `sync_artifact_to_graph`.

---

## Standard Stack

### Core (Already In Use — No New Packages Needed)
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| FastAPI BackgroundTasks | built-in | Async artifact generation after Understanding finalizes | Already used in `/api/generation/start` — proven pattern |
| SQLAlchemy async | in use | Artifact persistence with JSONB | All services use this already |
| `react-force-graph-2d` | in use | Force-directed graph rendering | `ForceGraphInner.tsx` already imports this |
| Anthropic Claude (via `create_tracked_llm`) | in use | LLM calls for generation | `RunnerReal` already uses this for all generation |
| LangChain messages (`HumanMessage`, `SystemMessage`) | in use | Prompt construction | All `RunnerReal` methods use this pattern |
| `_invoke_with_retry` + `_parse_json_response` | in use | Retry and JSON parsing | `llm_helpers.py` — already handles OverloadedError |

### Supporting (May Need)
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| `sonner` | in use | Toast notifications for generation status | Already imported in `useUnderstandingInterview.ts` |
| `lucide-react` | in use | Icons for progress steps | Already in all pages |
| React `useReducer` | built-in | Complex generation state (3 artifacts, each with retry count) | When `useState` chains get unwieldy |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| BackgroundTasks | Redis queue (existing QueueManager) | Queue adds Redis dependency and job lifecycle — BackgroundTasks is simpler for synchronous chains; QueueManager is for user-facing builds |
| SSE streaming | Polling GET endpoint | Polling is simpler to implement, SSE gives real-time feel; polling every 1-2s is acceptable for 15-30s generation |

**Installation:** No new packages required — everything is already installed.

---

## Architecture Patterns

### Existing System Architecture (What We're Extending)

```
backend/app/
├── agent/
│   ├── runner.py              # Protocol — add 3 new methods here
│   ├── runner_fake.py         # Test double — add 3 fake implementations
│   └── runner_real.py         # Production LLM — add 3 real implementations
├── schemas/
│   ├── artifacts.py           # ArtifactType enum — add 3 new types
│   └── understanding.py       # Already has IdeaBriefResponse
├── services/
│   ├── understanding_service.py  # finalize() triggers generation here
│   └── artifact_service.py    # Existing generate_all pattern
├── api/routes/
│   ├── understanding.py       # finalize_interview endpoint
│   └── artifacts.py           # Existing artifact endpoints
└── db/models/
    └── artifact.py            # One model, JSONB content — fits all 3 new types

frontend/src/
├── app/(dashboard)/projects/[id]/
│   ├── strategy/page.tsx      # Replace stub with real StrategyGraph from brief
│   ├── timeline/page.tsx      # Replace Kanban with personalized MVP timeline
│   └── architecture/page.tsx  # Replace session graph with tech stack display
├── components/
│   ├── strategy-graph/        # ForceGraphInner.tsx — extend node types
│   └── timeline/              # KanbanBoard — reuse for milestone view
└── hooks/
    └── useUnderstandingInterview.ts  # Add generation state here or new hook
```

### Pattern 1: Artifact Type Extension

The existing `ArtifactType` enum in `/backend/app/schemas/artifacts.py` uses `StrEnum`. Add three new types:

```python
# Source: /backend/app/schemas/artifacts.py (existing pattern)
class ArtifactType(StrEnum):
    # ... existing types ...
    STRATEGY_GRAPH = "strategy_graph"   # NEW: full strategy graph data
    MVP_TIMELINE = "mvp_timeline"       # NEW: milestone-based timeline
    APP_ARCHITECTURE = "app_architecture"  # NEW: tech stack + cost estimates
```

The `Artifact` model uses `UniqueConstraint("project_id", "artifact_type")` — one artifact per type per project. This is correct for our use case.

### Pattern 2: Runner Protocol Extension

Following the exact pattern of `generate_idea_brief` in `runner.py`:

```python
# Source: /backend/app/agent/runner.py (extend Protocol)
async def generate_strategy_graph(
    self,
    brief: dict,
    onboarding_answers: dict,
    understanding_answers: dict,
) -> dict:
    """Generate strategy graph nodes from brief and raw answers.

    Returns:
        Dict with keys: anchor_nodes (verbatim user words),
        strategy_nodes (LLM-derived), edges (connections)
    """
    ...

async def generate_mvp_timeline(
    self,
    brief: dict,
    onboarding_answers: dict,
) -> dict:
    """Generate milestone-based MVP timeline adapted to founder profile.

    Returns:
        Dict with keys: milestones (list), total_weeks, product_roadmap (list)
    """
    ...

async def generate_app_architecture(
    self,
    brief: dict,
    onboarding_answers: dict,
) -> dict:
    """Generate two-layer architecture with cost estimates.

    Returns:
        Dict with keys: components (high-level), tech_stack (recommendations),
        cost_estimates (startup/scale), integrations
    """
    ...
```

### Pattern 3: Auto-Trigger in finalize()

The `UnderstandingService.finalize()` already calls `sync_artifact_to_graph()` after saving the brief. We extend this same function:

```python
# Source: /backend/app/services/understanding_service.py — finalize() method
# After: await graph_service.sync_artifact_to_graph(artifact, ...)

# Trigger generation pipeline (non-fatal, uses background task pattern)
from app.services.artifact_generation_service import ArtifactGenerationService

gen_service = ArtifactGenerationService(runner=self.runner, session_factory=self.session_factory)
await gen_service.generate_personalized_artifacts(
    project_id=str(understanding.project_id),
    brief=brief_content,
    onboarding_answers=onboarding.answers,
    understanding_answers=understanding.answers,
    tier=tier_slug,
)
```

But this makes `finalize()` slow (blocks on LLM calls). Better pattern: **wrap in a try/except, non-blocking** — the HTTP response returns immediately with the brief, and a FastAPI `BackgroundTask` runs generation. The route handler needs to pass `BackgroundTasks` to the service.

The cleaner approach matching the codebase: add a `background_tasks: BackgroundTasks` parameter to `finalize_interview` route handler, pass it down, and use `background_tasks.add_task(...)` — **exactly matching `/api/generation/start`**.

### Pattern 4: Generation Status Polling

The existing `/api/generation/{job_id}/status` endpoint is for build jobs. For artifact generation, use the existing `generation_status` field on the `Artifact` model:

```
GET /api/artifacts/{project_id}/generation-status
→ Returns: {strategy_graph: "idle|generating|done|failed", mvp_timeline: "...", app_architecture: "..."}
```

The `Artifact.generation_status` column already has `idle | generating | failed` states. Add `done` as a terminal state convention (or use `idle` + `current_content != null` to mean done, matching existing `_artifact_graph_status()` in `graph_service.py`).

### Pattern 5: Frontend Generation Overlay

After `finalize_interview` succeeds (brief returns), the `useUnderstandingInterview` hook transitions to `viewing_brief`. We need a new state transition after the user sees the brief:

```
viewing_brief → [user proceeds to decision] → plan_selection → plan_selected
                                                              ↓
                                              [generation starts automatically]
                                              generating_artifacts
                                              ↓
                                              walkthrough (strategy → timeline → architecture)
```

The generation overlay is a separate component rendered on top. It polls `GET /api/artifacts/{project_id}/generation-status` every 2 seconds and shows:
- "Analyzing your idea..." (strategy_graph: generating)
- "Building your strategy..." (strategy_graph: done, mvp_timeline: generating)
- "Creating your timeline..." (mvp_timeline: done, app_architecture: generating)
- "Designing your architecture..." (app_architecture: generating → done)

### Pattern 6: Strategy Graph — Anchor Nodes from User Words

The existing `ForceGraphInner.tsx` renders `GraphNode` types: `decision | milestone | artifact`. Add a new type `anchor` (violet/bold) for verbatim user words. The `GraphNode` interface in `ForceGraphInner.tsx` needs extending:

```typescript
// Source: /frontend/src/components/strategy-graph/ForceGraphInner.tsx
export interface GraphNode {
  id: string;
  type: "decision" | "milestone" | "artifact" | "anchor" | "strategy";  // ADD anchor + strategy
  title: string;
  status: string;
  verbatim?: boolean;  // true = user's exact words, render with quotes styling
  x?: number;
  y?: number;
}
```

The backend `generate_strategy_graph` LLM prompt must:
1. Extract verbatim phrases from `onboarding_answers` and `understanding_answers`
2. Generate connecting strategy nodes (GTM steps, business model elements)
3. Return structured JSON with `anchor_nodes` (verbatim) and `strategy_nodes` (LLM-derived) and edges

### Anti-Patterns to Avoid

- **Blocking finalize() on generation**: LLM calls take 10-30s each. `finalize_interview` must return immediately with the brief. Use BackgroundTasks for generation.
- **Creating a new HTTP endpoint for generation trigger**: Trigger from within `finalize()` service layer, not from a separate client call. The auto-generation is invisible.
- **Rewriting architecture page from scratch**: The existing page loads from `?session` query param (build sessions). The new artifact-based architecture is a different display mode. Add a conditional: if `session` param → old build graph; if no `session` → show artifact-based architecture from brief.
- **Using Neo4j for the new strategy graph data**: The current strategy graph data in Neo4j is for `DecisionGate` nodes. The new "strategy from brief" graph is a **different visualization** — store as JSONB artifact in PostgreSQL, render directly without Neo4j. Neo4j stays as-is for decisions/milestones.
- **Calendar dates in timeline**: Locked decision: relative weeks only. Never use `new Date()` for milestone start/end dates.

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| LLM retry on overload | Custom retry loop | `_invoke_with_retry` from `llm_helpers.py` | Already handles `OverloadedError` with tenacity |
| JSON parse from LLM | Custom parser | `_parse_json_response` from `llm_helpers.py` | Handles markdown fences, whitespace |
| Auth on new endpoints | Custom middleware | `require_auth` dependency from `app.core.auth` | Clerk JWT verification, consistent pattern |
| Background task | Redis queue | FastAPI `BackgroundTasks` | Simpler for in-process tasks, already used |
| Artifact versioning | Custom versioning | Existing `Artifact.version_number` + `previous_content` | Already built, migrations exist |
| Token tracking | Raw LLM client | `create_tracked_llm` from `app.core.llm_config` | Tracks usage, emits metrics, applies tier |
| Force graph | Custom canvas | `react-force-graph-2d` | Already installed, `ForceGraphInner.tsx` wraps it |

**Key insight:** Every LLM call in this phase should go through `RunnerReal` methods that use `create_tracked_llm`, not raw Anthropic SDK calls. This ensures metering, tier routing, and retry consistency.

---

## Common Pitfalls

### Pitfall 1: finalize() Blocking on 3 LLM Calls
**What goes wrong:** Each LLM call (strategy, timeline, architecture) takes 10-30s. If called sequentially inside `finalize()`, the HTTP request times out (ALB/nginx default: 60s) or the user waits 90s for a response.
**Why it happens:** Straightforward sequential implementation.
**How to avoid:** Use `BackgroundTasks.add_task(gen_service.generate_all, ...)` — the route returns immediately with the brief, generation happens async.
**Warning signs:** `finalize_interview` route taking >5s in development.

### Pitfall 2: Strategy Graph Data Conflicts with Neo4j
**What goes wrong:** Developer stores new strategy graph nodes (from brief) in Neo4j using existing `GraphService`, which overwrites or conflicts with existing `DecisionGate` nodes on the same project.
**Why it happens:** Neo4j is the store for the existing strategy graph view. Adding new node types creates type ambiguity.
**How to avoid:** Store the new "strategy from brief" graph as a JSONB blob in the `Artifact` table (type: `strategy_graph`). The strategy page detects artifact existence and renders it **instead of** loading from Neo4j (or in addition, with clear visual separation). The existing Neo4j graph is for decisions/milestones — it stays.
**Warning signs:** `GET /api/graph/{project_id}` returning unexpected node types.

### Pitfall 3: Architecture Page Breaks Existing Build Flow
**What goes wrong:** The existing `/projects/:id/architecture` page uses `?session` query param to load build session plan steps. Replacing it breaks the build workflow.
**Why it happens:** Same URL, different data source.
**How to avoid:** Conditional rendering: `if (sessionId) → show build graph (current behavior); else → try to load app_architecture artifact → show personalized tech stack`. Both modes on same page, no URL changes needed.
**Warning signs:** Build flow navigation breaks after architecture page changes.

### Pitfall 4: Anchor Nodes Break Force Graph Layout
**What goes wrong:** Adding 20+ anchor nodes (verbatim user phrases) makes the force graph overcrowded and unreadable.
**Why it happens:** Verbatim quotes are often long strings; force graph tries to fit them all.
**How to avoid:** Limit anchor nodes to 5-8 key phrases extracted from answers. In the LLM prompt, instruct: "Extract the 5-7 most distinctive phrases from the user's answers — these become anchor nodes. Each should be ≤8 words."
**Warning signs:** Graph renders as a messy ball of overlapping text.

### Pitfall 5: Generation Status Polling Race Condition
**What goes wrong:** Frontend starts polling before BackgroundTask begins execution. Artifacts don't exist yet so polling returns 404 or empty.
**How to avoid:** In the `finalize_interview` route, before launching BackgroundTask, create all 3 artifact rows in DB with `generation_status="generating"` and `current_content=None`. Then start the background task. Polling can immediately find them.
**Warning signs:** First few polls return 404, UI shows confusing flicker.

### Pitfall 6: Timeline Uses Calendar Dates
**What goes wrong:** LLM generates timeline with specific dates ("January 2026: MVP launch").
**Why it happens:** LLMs default to calendar dates.
**How to avoid:** Prompt must explicitly state: "Use relative weeks only — never calendar dates. Example: 'Week 1-2: Validation'. The user decides when they start." Add a validation step: if any timeline item contains a year (4-digit number), regenerate.
**Warning signs:** Timeline items contain specific months or years.

### Pitfall 7: Tier Not Passed to New Generators
**What goes wrong:** New generator methods use `bootstrapper` tier for everyone, ignoring the user's actual subscription.
**Why it happens:** Tier injection pattern (`_tier` key in answers dict) is not obvious to new code.
**How to avoid:** All three new `RunnerReal` methods must extract `tier = brief.get("_tier", "bootstrapper")` — exactly matching `generate_idea_brief` and `generate_execution_options`. The brief dict passed to generation already has `_tier` injected by `finalize()`.
**Warning signs:** All users get identical detail levels regardless of tier.

---

## Code Examples

Verified patterns from existing codebase:

### BackgroundTasks Pattern (from generation.py)
```python
# Source: /backend/app/api/routes/generation.py
@router.post("/start", status_code=201, response_model=StartGenerationResponse)
async def start_generation(
    request: StartGenerationRequest,
    background_tasks: BackgroundTasks,  # <- inject this
    user: ClerkUser = Depends(require_build_subscription),
    redis=Depends(get_redis),
):
    # ... validation ...
    background_tasks.add_task(process_next_job, redis=redis)  # <- fire and forget
    return StartGenerationResponse(...)  # <- returns immediately
```

For Phase 22.1, the `finalize_interview` route becomes:
```python
@router.post("/{session_id}/finalize", response_model=IdeaBriefResponse)
async def finalize_interview(
    session_id: str,
    background_tasks: BackgroundTasks,  # ADD THIS
    user: ClerkUser = Depends(require_auth),
    runner: Runner = Depends(get_runner),
):
    # ... existing finalize logic ...
    result = await service.finalize(user.user_id, session_id)

    # Auto-trigger artifact generation (non-blocking)
    background_tasks.add_task(
        generate_personalized_artifacts,
        project_id=result["project_id"],
        brief=result["brief"],
        runner=runner,
    )

    return IdeaBriefResponse(brief=..., artifact_id=..., version=...)
```

### New RunnerReal Method Pattern
```python
# Source: /backend/app/agent/runner_real.py — follows generate_idea_brief pattern
async def generate_strategy_graph(
    self, brief: dict, onboarding_answers: dict, understanding_answers: dict
) -> dict:
    user_id = brief.get("_user_id", "system")
    session_id = brief.get("_session_id", "default")
    tier = brief.get("_tier", "bootstrapper")

    # Extract verbatim anchor quotes from answers
    all_answers = {**onboarding_answers, **understanding_answers}
    answers_text = "\n".join(f"- {v}" for v in all_answers.values() if v)

    llm = await create_tracked_llm(user_id=user_id, role="architect", session_id=session_id)

    task_instructions = """Generate a strategy graph from the founder's answers.

Extract 5-7 key verbatim phrases from their answers — these become anchor nodes.
Generate 8-12 strategy nodes connecting their words to a full business strategy.

Return ONLY JSON:
{
  "anchor_nodes": [{"id": "a1", "type": "anchor", "title": "user's exact words", "verbatim": true}],
  "strategy_nodes": [{"id": "s1", "type": "strategy", "title": "Strategic insight", "category": "gtm|business_model|product|risk"}],
  "edges": [{"from": "a1", "to": "s1", "relation": "validates"}]
}"""
    # ... standard invoke + retry pattern ...
```

### Artifact Generation Status Endpoint
```python
# New endpoint to add to /backend/app/api/routes/artifacts.py
@router.get("/{project_id}/generation-status")
async def get_generation_status(
    project_id: uuid.UUID,
    user: ClerkUser = Depends(require_auth),
) -> dict:
    """Poll artifact generation status for personalized artifacts."""
    # Verify project ownership (existing pattern)
    # Load 3 artifact types: strategy_graph, mvp_timeline, app_architecture
    # Return {strategy_graph: "generating|done|failed|pending", ...}
```

### Frontend Polling Hook Pattern
```typescript
// New hook: useArtifactGeneration.ts — follows useBuildProgress.ts pattern
function useArtifactGeneration(projectId: string, enabled: boolean) {
  const [status, setStatus] = useState<GenerationStatus | null>(null);
  const { getToken } = useAuth();

  useEffect(() => {
    if (!enabled || !projectId) return;

    const interval = setInterval(async () => {
      const res = await apiFetch(`/api/artifacts/${projectId}/generation-status`, getToken);
      if (res.ok) {
        const data = await res.json();
        setStatus(data);
        // Stop polling when all done or failed
        if (data.all_complete) clearInterval(interval);
      }
    }, 2000);

    return () => clearInterval(interval);
  }, [enabled, projectId, getToken]);

  return status;
}
```

### Strategy Graph Display — Distinguish Anchor vs Strategy Nodes
```typescript
// Extend NODE_COLORS in /frontend/src/components/strategy-graph/ForceGraphInner.tsx
const NODE_COLORS = {
  decision: "#8B5CF6",   // violet (existing)
  milestone: "#10B981",  // emerald (existing)
  artifact: "#3B82F6",   // blue (existing)
  anchor: "#F59E0B",     // amber — user's own words (NEW)
  strategy: "#EC4899",   // pink — LLM-derived strategy nodes (NEW)
} as const;
```

---

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Strategy graph shows Neo4j decision nodes | Phase 22.1: Also shows brief-derived strategy visualization | Phase 22.1 | New visualization layer, existing Neo4j data untouched |
| Architecture page requires `?session` param | Phase 22.1: Also shows artifact-based tech stack when no session | Phase 22.1 | Dual-mode page |
| Timeline shows system events (Kanban) | Phase 22.1: Also shows personalized MVP milestone timeline | Phase 22.1 | Personalized primary view |
| Understanding completes → manual navigation to artifacts | Phase 22.1: Auto-generation immediately after brief | Phase 22.1 | Core UX improvement |

---

## Current State Audit (What Exists vs What's Needed)

### Exists (Working)
| Component | Location | Status |
|-----------|----------|--------|
| `UnderstandingService.finalize()` | `backend/app/services/understanding_service.py` | Working — generates `IDEA_BRIEF` artifact |
| `Artifact` model with JSONB | `backend/app/db/models/artifact.py` | Working — `generation_status`, versioning |
| `ArtifactType` enum | `backend/app/schemas/artifacts.py` | Working — extend with 3 new types |
| `Runner` protocol | `backend/app/agent/runner.py` | Working — add 3 new methods |
| `RunnerReal` with LLM | `backend/app/agent/runner_real.py` | Working — add 3 new implementations |
| `StrategyGraphCanvas` + `ForceGraphInner` | `frontend/src/components/strategy-graph/` | Working — read-only force graph |
| `KanbanBoard` + `TimelineCard` | `frontend/src/components/timeline/` | Working — reusable for milestone view |
| `BackgroundTasks` pattern | `backend/app/api/routes/generation.py` | Working — copy this pattern |
| `apiFetch` + Clerk auth | `frontend/src/lib/api.ts` | Working — use for polling |

### Gap (Must Build for Phase 22.1)
| Component | What's Missing |
|-----------|----------------|
| `ArtifactType.STRATEGY_GRAPH`, `MVP_TIMELINE`, `APP_ARCHITECTURE` | Not in enum |
| `Runner.generate_strategy_graph()` | Not in protocol |
| `Runner.generate_mvp_timeline()` | Not in protocol |
| `Runner.generate_app_architecture()` | Not in protocol |
| `RunnerReal` implementations of the 3 above | Not implemented |
| `RunnerFake` implementations of the 3 above | Not implemented |
| Auto-trigger in `finalize_interview` route | Not wired |
| `GET /api/artifacts/{project_id}/generation-status` | Not built |
| Generation progress overlay UI component | Not built |
| Guided walkthrough UI (step through 3 artifacts) | Not built |
| Strategy graph page: display from `strategy_graph` artifact | Only shows Neo4j graph (empty for new users) |
| Timeline page: display MVP milestones from `mvp_timeline` artifact | Only shows system event Kanban |
| Architecture page: display tech stack from `app_architecture` artifact | Only shows build session graph |

---

## Open Questions

1. **Where exactly does auto-generation trigger?**
   - What we know: `finalize_interview` route is the entry point. `BackgroundTasks` is the mechanism.
   - What's unclear: Does the trigger go in the route handler or the `UnderstandingService`?
   - Recommendation: Route handler injects `BackgroundTasks` and passes it to a new `schedule_artifact_generation()` function. Service layer stays pure (no BackgroundTasks dependency). This matches the `generation.py` pattern exactly.

2. **Does the strategy_graph artifact replace or augment the Neo4j strategy graph?**
   - What we know: Neo4j stores `Decision` and `Milestone` nodes from `DecisionGate` and `StageEvent`. The new strategy graph needs user-word anchor nodes + strategy nodes.
   - What's unclear: Should `/api/graph/{project_id}` merge both data sources?
   - Recommendation: Keep them separate. The strategy page shows the **brief-derived graph** (from the `strategy_graph` artifact) as the primary view when the artifact exists. The Neo4j-based graph (existing endpoint) becomes a secondary tab/toggle. This avoids Neo4j schema changes.

3. **Retry logic: 3 silent retries means retrying at what level?**
   - What we know: `_invoke_with_retry` handles Anthropic overload retries. But the phase says "retry silently up to 3 times."
   - Recommendation: Interpret as generation-level retry (retry the entire artifact generation if it fails), not just LLM call level. The background task wraps the 3-artifact generation in a try/except with 3 attempts total. On permanent failure, set all artifacts to `generation_status="failed"` and the UI shows an error option to retry.

4. **Timeline: two views or one view?**
   - What we know: Context says "Detailed MVP launch timeline as primary view, with a lighter long-term product roadmap section."
   - Recommendation: Single page with two sections: MVP Timeline (detailed milestones with deliverables) scrolls into Product Roadmap (lighter 3-phase view). The existing Kanban board stays below both (system events).

5. **Architecture page: what happens when user has no `app_architecture` artifact yet?**
   - Recommendation: Show the same empty state as current (`/projects/:id/architecture` with "No architecture yet" message) but with a clear message "Your app architecture is being generated..." if generation is in progress.

---

## Sources

### Primary (HIGH confidence)
- Direct codebase inspection: `/backend/app/agent/runner.py` — Runner protocol (10 methods confirmed)
- Direct codebase inspection: `/backend/app/agent/runner_real.py` — all LLM generation patterns
- Direct codebase inspection: `/backend/app/services/understanding_service.py` — `finalize()` flow
- Direct codebase inspection: `/backend/app/api/routes/generation.py` — BackgroundTasks pattern
- Direct codebase inspection: `/backend/app/schemas/artifacts.py` — ArtifactType enum and 7 existing types
- Direct codebase inspection: `/backend/app/db/models/artifact.py` — Artifact model with JSONB + generation_status
- Direct codebase inspection: `/frontend/src/components/strategy-graph/ForceGraphInner.tsx` — react-force-graph-2d usage
- Direct codebase inspection: `/frontend/src/app/(dashboard)/projects/[id]/understanding/page.tsx` — current Understanding page states
- Direct codebase inspection: `/frontend/src/app/(dashboard)/projects/[id]/strategy/page.tsx` — current strategy page (loads from `/api/graph/{id}`)
- Direct codebase inspection: `/frontend/src/app/(dashboard)/projects/[id]/architecture/page.tsx` — requires `?session` param

---

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH — all libraries verified by direct import inspection in codebase
- Architecture: HIGH — patterns derived from existing working code, not docs
- Pitfalls: HIGH — derived from actual code structure and identified gaps
- New LLM prompts: MEDIUM — prompt engineering for the 3 new generators needs iteration

**Research date:** 2026-02-21
**Valid until:** 2026-03-21 (stable stack, no fast-moving dependencies)
