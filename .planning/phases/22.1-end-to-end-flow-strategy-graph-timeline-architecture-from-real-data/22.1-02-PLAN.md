---
phase: 22.1-end-to-end-flow
plan: 02
type: execute
wave: 2
depends_on:
  - "22.1-01"
files_modified:
  - backend/app/agent/runner_real.py
  - backend/app/api/routes/understanding.py
  - backend/app/services/understanding_service.py
  - backend/app/api/routes/artifacts.py
autonomous: true
requirements:
  - E2E-GENERATE
  - E2E-TRIGGER
must_haves:
  truths:
    - "After finalize_interview returns, 3 artifact rows exist with generation_status=generating"
    - "Background task generates all 3 artifacts using RunnerReal (or RunnerFake in dev)"
    - "GET /api/artifacts/{project_id}/generation-status returns status for all 3 artifact types"
    - "Generation retries silently up to 3 times on LLM failure"
    - "RunnerReal generates personalized content from actual user brief data"
  artifacts:
    - path: "backend/app/agent/runner_real.py"
      provides: "3 real LLM generation methods"
      contains: "generate_strategy_graph|generate_mvp_timeline|generate_app_architecture"
    - path: "backend/app/api/routes/understanding.py"
      provides: "Auto-trigger generation after finalize"
      contains: "BackgroundTasks|_background_generate_e2e_artifacts"
    - path: "backend/app/api/routes/artifacts.py"
      provides: "Generation status polling endpoint"
      contains: "generation-status"
  key_links:
    - from: "backend/app/api/routes/understanding.py"
      to: "backend/app/services/understanding_service.py"
      via: "finalize returns brief, route creates artifact rows + background task"
      pattern: "background_tasks.add_task.*_background_generate"
    - from: "backend/app/api/routes/artifacts.py"
      to: "backend/app/db/models/artifact.py"
      via: "status endpoint queries artifacts by project_id and type"
      pattern: "generation-status.*ArtifactType"
---

<objective>
Wire the end-to-end generation pipeline: finalize_interview auto-triggers background generation of 3 personalized artifacts, with a polling endpoint for the frontend.

Purpose: This is the core plumbing that makes the "magic happens automatically" experience work. After Understanding completes, the system immediately starts generating personalized Strategy Graph, Timeline, and Architecture artifacts without any manual trigger.

Output: RunnerReal with 3 LLM generation methods, auto-trigger from finalize_interview, generation status polling endpoint.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22.1-end-to-end-flow-strategy-graph-timeline-architecture-from-real-data/22.1-01-SUMMARY.md
@backend/app/agent/runner_real.py
@backend/app/api/routes/understanding.py
@backend/app/services/understanding_service.py
@backend/app/api/routes/artifacts.py
@backend/app/schemas/artifacts.py
@backend/app/db/models/artifact.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement RunnerReal LLM generation for 3 new artifact types</name>
  <files>
    backend/app/agent/runner_real.py
  </files>
  <action>
    Add 3 new methods to `RunnerReal`, following the exact pattern of existing methods (create_tracked_llm, SystemMessage(COFOUNDER_SYSTEM), HumanMessage with prompt, _invoke_with_retry, _parse_json_response):

    **generate_strategy_graph(self, idea, brief, onboarding_answers):**
    System: COFOUNDER_SYSTEM
    Prompt:
    - Include the full idea text and brief content
    - Instruct: "Extract 5-8 key phrases VERBATIM from the founder's answers — these become anchor nodes. The user must recognize their exact words."
    - Instruct: "Create 8-12 strategy nodes connecting the anchors: go-to-market steps, business model components, competitive moat elements, validation milestones"
    - Instruct: "Create edges showing relationships between anchors and strategy nodes"
    - JSON schema: `{nodes: [{id, type: "anchor"|"strategy", label, description, status: "validated"|"planned"}], edges: [{source, target, relation}], anchor_phrases: [str]}`
    - Silent JSON retry on parse failure (existing pattern)

    **generate_mvp_timeline(self, idea, brief, tier):**
    System: COFOUNDER_SYSTEM
    Prompt:
    - Include idea, brief, and tier
    - Tier-based adaptation: bootstrapper = smaller MVP scope + longer phases (8-12 weeks), partner = moderate (6-8 weeks), cto_scale = aggressive (4-6 weeks)
    - Instruct: "Use RELATIVE WEEKS only (Week 1, Week 3), never calendar dates — the founder decides when to start"
    - Instruct: "Each milestone must list 2-3 CONCRETE deliverables (e.g., 'landing page', '50 signups', 'user interviews')"
    - Instruct: "Adapt both scope AND duration to {tier} tier"
    - JSON schema: `{milestones: [{week, title, deliverables: [str], duration_weeks, description}], long_term_roadmap: [{phase, title, description, estimated_weeks}], total_mvp_weeks, adapted_for}`

    **generate_app_architecture(self, idea, brief, tier):**
    System: COFOUNDER_SYSTEM
    Prompt:
    - Include idea and brief
    - Instruct: "Simplified by default for non-technical founders. Use plain English component names."
    - Instruct: "Include rough cost estimates: startup monthly (~$50/mo) and scale monthly (~$200/mo at 1k users)"
    - Instruct: "For each component, recommend a specific technology and list 1-2 alternatives"
    - JSON schema: `{components: [{name, type: "frontend"|"backend"|"database"|"auth"|"storage"|"other", description, tech_recommendation, alternatives: [str], detail_level: "simplified"|"expanded"}], connections: [{from_component, to_component, protocol, description}], cost_estimate: {startup_monthly, scale_monthly, breakdown: [{component, cost, note}]}, integration_recommendations: [str]}`

    All 3 methods: use `_invoke_with_retry` for the LLM call, `_parse_json_response` for parsing, silent JSON retry on first parse failure. Tier is passed from the service layer via the brief dict's `_tier` key or as direct parameter.
  </action>
  <verify>
    Verify the methods exist and have correct signatures:
    ```bash
    cd /Users/vladcortex/co-founder/backend && python -c "
    from app.agent.runner_real import RunnerReal
    import inspect
    for method_name in ['generate_strategy_graph', 'generate_mvp_timeline', 'generate_app_architecture']:
        method = getattr(RunnerReal, method_name)
        sig = inspect.signature(method)
        print(f'{method_name}: {sig}')
    "
    ```
    All 3 methods have correct parameter names matching Runner protocol.
  </verify>
  <done>RunnerReal has 3 new methods with LLM prompts that extract verbatim user phrases for strategy graph, adapt timeline to tier, and include cost estimates in architecture. All use existing _invoke_with_retry and _parse_json_response patterns.</done>
</task>

<task type="auto">
  <name>Task 2: Wire auto-trigger from finalize + generation status endpoint</name>
  <files>
    backend/app/api/routes/understanding.py
    backend/app/services/understanding_service.py
    backend/app/api/routes/artifacts.py
  </files>
  <action>
    **In `backend/app/api/routes/understanding.py`:**

    1. Add `BackgroundTasks` import from fastapi
    2. Modify `finalize_interview` endpoint signature to accept `background_tasks: BackgroundTasks`
    3. After `service.finalize()` returns successfully:
       - Create 3 artifact rows with `generation_status="generating"` BEFORE launching background task (avoids polling race condition per research anti-pattern 5)
       - Call `background_tasks.add_task(_background_generate_e2e_artifacts, ...)` with project_id, user_id, runner, brief content, idea text, tier, onboarding_answers
    4. Add the background task function `_background_generate_e2e_artifacts`:
       ```python
       async def _background_generate_e2e_artifacts(
           project_id: UUID,
           user_id: str,
           runner: Runner,
           idea: str,
           brief: dict,
           tier: str,
           onboarding_answers: dict,
       ):
           """Background generation of Strategy Graph, Timeline, and Architecture."""
           session_factory = get_session_factory()
           artifact_types_and_generators = [
               (ArtifactType.STRATEGY_GRAPH, "generate_strategy_graph", {"idea": idea, "brief": brief, "onboarding_answers": onboarding_answers}),
               (ArtifactType.MVP_TIMELINE, "generate_mvp_timeline", {"idea": idea, "brief": brief, "tier": tier}),
               (ArtifactType.APP_ARCHITECTURE, "generate_app_architecture", {"idea": idea, "brief": brief, "tier": tier}),
           ]

           for artifact_type, method_name, kwargs in artifact_types_and_generators:
               max_retries = 3
               for attempt in range(max_retries):
                   try:
                       content = await getattr(runner, method_name)(**kwargs)
                       # Update artifact row with generated content
                       async with session_factory() as session:
                           result = await session.execute(
                               select(Artifact).where(
                                   Artifact.project_id == project_id,
                                   Artifact.artifact_type == artifact_type.value,
                               )
                           )
                           artifact = result.scalar_one_or_none()
                           if artifact:
                               artifact.current_content = content
                               artifact.generation_status = "idle"
                               flag_modified(artifact, "current_content")
                               await session.commit()
                       break  # Success, move to next artifact
                   except Exception as e:
                       if attempt == max_retries - 1:
                           # All retries failed — mark as failed
                           async with session_factory() as session:
                               result = await session.execute(
                                   select(Artifact).where(
                                       Artifact.project_id == project_id,
                                       Artifact.artifact_type == artifact_type.value,
                                   )
                               )
                               artifact = result.scalar_one_or_none()
                               if artifact:
                                   artifact.generation_status = "failed"
                                   await session.commit()
                           import logging
                           logging.getLogger(__name__).warning(
                               "E2E artifact generation failed after %d retries: %s — %s",
                               max_retries, artifact_type.value, str(e),
                           )
       ```

    5. The pre-creation of artifact rows happens in the finalize_interview route AFTER finalize() returns, BEFORE background_tasks.add_task(). The finalize service returns `project_id` in its result dict (added in the service change below). Create the rows with:
       ```python
       project_id = UUID(result["project_id"])
       async with session_factory() as session:
           for at in [ArtifactType.STRATEGY_GRAPH, ArtifactType.MVP_TIMELINE, ArtifactType.APP_ARCHITECTURE]:
               artifact = Artifact(
                   project_id=project_id,
                   artifact_type=at.value,
                   current_content=None,
                   version_number=1,
                   schema_version=1,
                   generation_status="generating",
               )
               session.add(artifact)
           await session.commit()
       ```

    **In `backend/app/services/understanding_service.py`:**
    - In the `finalize` method, add `"project_id": str(understanding.project_id)` to the return dict alongside brief, artifact_id, version
    - Also add `"idea_text": onboarding.idea_text` and `"onboarding_answers": onboarding.answers or {}` to the return dict
    - Also add `"tier": tier_slug` to the return dict
    These are needed by the route to pass to the background task without re-querying the database.

    **In `backend/app/api/routes/artifacts.py`:**
    Add a new endpoint:
    ```python
    @router.get("/project/{project_id}/generation-status")
    async def get_e2e_generation_status(
        project_id: UUID,
        user: ClerkUser = Depends(require_auth),
    ):
        """Get generation status for the 3 E2E artifacts (Strategy Graph, Timeline, Architecture).

        Returns status for each artifact type. Frontend polls this every 2 seconds.
        """
        session_factory = get_session_factory()
        async with session_factory() as session:
            # Verify project ownership
            result = await session.execute(
                select(Project).where(
                    Project.id == project_id,
                    Project.clerk_user_id == user.user_id,
                )
            )
            if result.scalar_one_or_none() is None:
                raise HTTPException(status_code=404, detail="Project not found")

            # Get status for all 3 E2E artifact types
            e2e_types = [ArtifactType.STRATEGY_GRAPH, ArtifactType.MVP_TIMELINE, ArtifactType.APP_ARCHITECTURE]
            statuses = {}
            for at in e2e_types:
                result = await session.execute(
                    select(Artifact).where(
                        Artifact.project_id == project_id,
                        Artifact.artifact_type == at.value,
                    )
                )
                artifact = result.scalar_one_or_none()
                statuses[at.value] = {
                    "status": artifact.generation_status if artifact else "not_started",
                    "has_content": artifact.current_content is not None if artifact else False,
                }

            all_done = all(s["status"] == "idle" and s["has_content"] for s in statuses.values())
            any_failed = any(s["status"] == "failed" for s in statuses.values())

            return {
                "artifacts": statuses,
                "all_complete": all_done,
                "any_failed": any_failed,
            }
    ```

    IMPORTANT: This new endpoint MUST be registered BEFORE the existing `/{artifact_id}` route in the router to avoid path conflicts. Place it right after the `POST /generate` endpoint.

    Also import `ArtifactType` and `Project` at the top of artifacts.py if not already imported.
  </action>
  <verify>
    1. Verify finalize route now accepts BackgroundTasks:
    ```bash
    cd /Users/vladcortex/co-founder/backend && python -c "
    import inspect
    from app.api.routes.understanding import finalize_interview
    sig = inspect.signature(finalize_interview)
    print('background_tasks' in sig.parameters)
    "
    ```
    2. Verify generation-status endpoint exists:
    ```bash
    cd /Users/vladcortex/co-founder/backend && python -c "
    from app.api.routes.artifacts import router
    routes = [r.path for r in router.routes]
    print('/project/{project_id}/generation-status' in routes)
    "
    ```
    3. Verify understanding_service.finalize returns project_id:
    ```bash
    cd /Users/vladcortex/co-founder/backend && python -c "
    import inspect
    from app.services.understanding_service import UnderstandingService
    src = inspect.getsource(UnderstandingService.finalize)
    print('project_id' in src and 'idea_text' in src and 'onboarding_answers' in src)
    "
    ```
  </verify>
  <done>finalize_interview auto-creates 3 artifact rows with generation_status="generating" and launches background task. Background task generates each artifact with 3 silent retries. GET /api/artifacts/project/{project_id}/generation-status returns per-artifact status with all_complete and any_failed flags.</done>
</task>

</tasks>

<verification>
- finalize_interview endpoint creates 3 "generating" artifact rows before returning response
- Background task calls runner.generate_strategy_graph, generate_mvp_timeline, generate_app_architecture
- Failed generation after 3 retries marks artifact as "failed" (user never sees the error unless all retries fail)
- GET /api/artifacts/project/{id}/generation-status returns correct status for all 3 types
- Existing finalize flow (IDEA_BRIEF creation) is not broken
- No existing tests broken
</verification>

<success_criteria>
Complete backend pipeline: finalize triggers auto-generation, 3 artifacts generated in background with retry, status polling endpoint works. The "magic just happens" experience is wired on the backend.
</success_criteria>

<output>
After completion, create `.planning/phases/22.1-end-to-end-flow-strategy-graph-timeline-architecture-from-real-data/22.1-02-SUMMARY.md`
</output>
