---
phase: 10-export-deploy-readiness-e2e-testing
plan: 10
type: tdd
wave: 5
depends_on: ["10-04", "10-05", "10-06", "10-07"]
files_modified:
  - backend/tests/e2e/test_founder_flow.py
  - backend/tests/e2e/conftest.py
  - backend/tests/conftest.py
autonomous: true

must_haves:
  truths:
    - "E2E test exercises full founder flow from idea to preview"
    - "Test uses RunnerFake + FakeSandboxRuntime + FakeAsyncRedis (no real APIs)"
    - "Test verifies job progresses through all states to READY"
    - "Test verifies dashboard shows MVP Built stage and product_version"
    - "Test verifies timeline contains MVP Built entry"
    - "Test completes in under 60 seconds"
  artifacts:
    - path: "backend/tests/e2e/test_founder_flow.py"
      provides: "End-to-end founder flow test"
      contains: "test_full_founder_flow"
    - path: "backend/tests/e2e/conftest.py"
      provides: "E2E test fixtures"
      contains: "FakeSandboxRuntime"
  key_links:
    - from: "backend/tests/e2e/test_founder_flow.py"
      to: "backend/app/api/routes/generation.py"
      via: "POST /api/generation/start"
      pattern: "generation/start"
    - from: "backend/tests/e2e/test_founder_flow.py"
      to: "backend/app/api/routes/dashboard.py"
      via: "GET /api/dashboard/{project_id}"
      pattern: "dashboard"
---

<objective>
Comprehensive E2E test exercising the full founder flow from idea to preview.

Purpose: Success Criteria #17 (end-to-end founder flow test completes successfully). This single test validates the entire Phase 10 integration by walking through the complete founder journey using test doubles for external services.

Output: E2E test that exercises idea → onboarding → brief → gate 1 → execution plan → build → preview → dashboard verification.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-export-deploy-readiness-e2e-testing/10-RESEARCH.md

@backend/tests/conftest.py
@backend/app/agent/runner_fake.py
@backend/app/api/routes/generation.py
@backend/app/api/routes/dashboard.py
@backend/app/api/routes/jobs.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: E2E test fixtures and FakeSandboxRuntime</name>
  <files>backend/tests/e2e/conftest.py, backend/tests/e2e/__init__.py</files>
  <action>
    Create `backend/tests/e2e/__init__.py` (empty).

    Create `backend/tests/e2e/conftest.py` with shared E2E test fixtures:

    **FakeSandboxRuntime:**
    Complete test double for E2BSandboxRuntime that implements the same interface:
    ```python
    class FakeSandboxRuntime:
        """Test double for E2BSandboxRuntime — no real E2B API calls."""

        def __init__(self, template: str = "base"):
            self.template = template
            self.files: dict[str, str] = {}
            self._started = False
            self._background_procs: dict[str, str] = {}

        @asynccontextmanager
        async def session(self):
            await self.start()
            try:
                yield self
            finally:
                await self.stop()

        async def start(self):
            self._started = True

        async def stop(self):
            self._started = False

        async def write_file(self, path: str, content: str):
            abs_path = path if path.startswith("/") else f"/home/user/{path}"
            self.files[abs_path] = content

        async def read_file(self, path: str) -> str:
            abs_path = path if path.startswith("/") else f"/home/user/{path}"
            return self.files.get(abs_path, "")

        async def list_files(self, path: str = "/") -> list[str]:
            return list(self.files.keys())

        async def make_dir(self, path: str):
            pass

        async def run_command(self, command: str, timeout: int = 120, cwd: str | None = None) -> dict:
            return {"stdout": "ok", "stderr": "", "exit_code": 0}

        async def run_background(self, command: str, cwd: str | None = None) -> str:
            pid = "fake-pid-001"
            self._background_procs[pid] = command
            return pid

        async def kill_process(self, pid: str):
            self._background_procs.pop(pid, None)

        async def install_packages(self, packages: list[str], manager: str = "pip") -> dict:
            return {"stdout": "installed", "stderr": "", "exit_code": 0}

        class _FakeSandbox:
            sandbox_id = "fake-sandbox-e2e-001"
            def get_host(self, port): return f"{port}-fake-sandbox-e2e-001.e2b.app"
            def set_timeout(self, t): pass

        @property
        def _sandbox(self):
            return self._FakeSandbox()
    ```

    **E2E client fixture:**
    ```python
    @pytest.fixture
    async def e2e_client(fake_db_session, fake_redis):
        """Full-stack test client with all dependencies overridden."""
        from app.main import app
        from app.db.base import get_session_factory
        from app.db.redis import get_redis
        from app.agent.deps import get_runner
        from app.agent.runner_fake import RunnerFake

        runner = RunnerFake()
        sandbox = FakeSandboxRuntime()

        # Override all external dependencies
        app.dependency_overrides[get_redis] = lambda: fake_redis
        app.dependency_overrides[get_runner] = lambda: runner
        # Override auth to return a test user
        app.dependency_overrides[require_auth] = lambda: ClerkUser(user_id="e2e-test-user", ...)
        app.dependency_overrides[require_subscription] = lambda: ClerkUser(user_id="e2e-test-user", ...)

        async with AsyncClient(app=app, base_url="http://test") as client:
            yield client

        app.dependency_overrides.clear()
    ```

    Adapt the fixture pattern from existing `backend/tests/conftest.py` — use aiosqlite for in-memory DB, FakeAsyncRedis for Redis.
  </action>
  <verify>
    `cd /Users/vladcortex/co-founder && python -c "from tests.e2e.conftest import FakeSandboxRuntime; print('OK')"` — imports successfully.
  </verify>
  <done>FakeSandboxRuntime and E2E client fixture created with all external dependencies overridden.</done>
</task>

<task type="auto">
  <name>Task 2: E2E founder flow test</name>
  <files>backend/tests/e2e/test_founder_flow.py</files>
  <action>
    Write the comprehensive E2E test in `backend/tests/e2e/test_founder_flow.py`:

    ```python
    @pytest.mark.asyncio
    async def test_full_founder_flow(e2e_client):
        """
        E2E: Complete founder flow from idea to preview.

        Exercises the full journey to validate Phase 10 integration:
        1. Onboarding: capture idea
        2. Understanding: interview + brief generation
        3. Gate 1: proceed decision
        4. Execution plan: generate + select
        5. Build: submit job → worker processes → READY
        6. Dashboard: verify MVP Built state
        7. Timeline: verify MVP Built entry

        Uses RunnerFake + FakeSandboxRuntime — no real LLM or E2B calls.
        """
        client = e2e_client

        # === Step 1: Start onboarding ===
        resp = await client.post("/api/onboarding/start", json={
            "idea_text": "A marketplace for local artisans to sell handmade goods"
        })
        assert resp.status_code == 201
        session_id = resp.json()["session_id"]
        project_id = resp.json()["project_id"]

        # === Step 2: Submit onboarding answers ===
        resp = await client.post(f"/api/onboarding/{session_id}/submit", json={
            "answers": {"q1": "Local artisans", "q2": "Commission-based"}
        })
        assert resp.status_code == 200

        # === Step 3: Understanding interview ===
        resp = await client.post(f"/api/understanding/start", json={
            "project_id": project_id
        })
        assert resp.status_code in [200, 201]
        understanding_id = resp.json().get("session_id")

        # Submit understanding answers
        resp = await client.post(f"/api/understanding/{understanding_id}/submit", json={
            "answers": {"uq1": "Mobile-first", "uq2": "Stripe payments"}
        })
        assert resp.status_code == 200

        # Generate brief
        resp = await client.post(f"/api/understanding/{understanding_id}/generate-brief")
        assert resp.status_code == 200

        # === Step 4: Gate 1 — proceed ===
        resp = await client.post("/api/gates", json={
            "project_id": project_id,
            "gate_type": "direction"
        })
        assert resp.status_code in [200, 201]
        gate_id = resp.json()["gate_id"]

        resp = await client.post(f"/api/gates/{gate_id}/resolve", json={
            "decision": "proceed"
        })
        assert resp.status_code == 200

        # === Step 5: Execution plan ===
        resp = await client.post("/api/plans", json={
            "project_id": project_id
        })
        assert resp.status_code in [200, 201]
        plan_id = resp.json().get("plan_id") or resp.json().get("artifact_id")

        # Select fast-mvp option
        resp = await client.post(f"/api/plans/{plan_id}/select", json={
            "option_id": "fast_mvp"
        })
        assert resp.status_code == 200

        # === Step 6: Start generation build ===
        resp = await client.post("/api/generation/start", json={
            "project_id": project_id,
            "goal": "Build the artisan marketplace MVP"
        })
        assert resp.status_code in [200, 201]
        job_id = resp.json()["job_id"]
        assert resp.json()["status"] == "queued"  # GENR-01

        # === Step 7: Wait for build to complete ===
        # In test, worker processes synchronously via BackgroundTasks
        # Poll status until terminal
        import asyncio
        for _ in range(30):  # Max 30 polls
            resp = await client.get(f"/api/generation/{job_id}/status")
            assert resp.status_code == 200
            status = resp.json()["status"]
            if status in ["ready", "failed"]:
                break
            await asyncio.sleep(0.1)

        assert status == "ready", f"Expected ready, got {status}"  # GENR-02
        assert resp.json().get("preview_url") is not None  # GENR-04
        assert "build_v0_1" in resp.json().get("build_version", "")  # GENR-05

        # === Step 8: Verify dashboard ===
        resp = await client.get(f"/api/dashboard/{project_id}")
        assert resp.status_code == 200
        dashboard = resp.json()
        assert dashboard["stage"] == 3  # MVP Built (MVPS-01)
        assert dashboard["product_version"] == "v0.1"  # MVPS-02
        assert dashboard["mvp_completion_percent"] > 0  # MVPS-02
        assert dashboard["preview_url"] is not None  # Has preview
        assert isinstance(dashboard["artifacts"], list)  # CNTR-02
        assert isinstance(dashboard["pending_decisions"], list)  # CNTR-02
        assert isinstance(dashboard["risk_flags"], list)  # CNTR-02

        # === Step 9: Verify timeline ===
        resp = await client.get(f"/api/timeline/{project_id}")
        assert resp.status_code == 200
        timeline = resp.json()
        items = timeline.get("items", [])
        mvp_event = next((i for i in items if "mvp" in i.get("title", "").lower() or "mvp" in i.get("type", "").lower()), None)
        assert mvp_event is not None, "Timeline should contain MVP Built entry"  # MVPS-03
    ```

    **Important notes for the test:**
    - The worker in test mode runs via BackgroundTasks which processes in the same event loop — the job should complete by the time we poll.
    - If BackgroundTasks doesn't trigger in tests, manually call `process_next_job(runner=RunnerFake(), redis=fake_redis)` inline.
    - Adapt endpoint paths to match actual registered routes (may need to check main.py for prefixes).
    - If any step 404s, it may mean the endpoint doesn't exist yet or the route prefix differs — adjust accordingly.
    - The test should complete in under 60 seconds (success criteria).
  </action>
  <verify>
    `cd /Users/vladcortex/co-founder && python -m pytest backend/tests/e2e/test_founder_flow.py -v --timeout=60` — test passes within 60 seconds.
  </verify>
  <done>E2E test exercises full founder flow. All success criteria verified: job_id returned, build progresses to READY, dashboard shows MVP Built, timeline has entry. Test uses only fake doubles.</done>
</task>

</tasks>

<verification>
- E2E test runs without any real API calls (E2B, Anthropic, Clerk)
- Full flow: idea → onboarding → understanding → gate → plan → build → preview
- Dashboard verification: stage=3, product_version=v0.1, completion > 0
- Timeline verification: MVP Built entry exists
- Response contracts verified inline (lists are lists, not null)
- Test completes in < 60 seconds
</verification>

<success_criteria>
- `python -m pytest backend/tests/e2e/test_founder_flow.py -v --timeout=60` — passes
- No real external service calls made during test
- All GENR, MVPS, CNTR success criteria validated by assertions
</success_criteria>

<output>
After completion, create `.planning/phases/10-export-deploy-readiness-e2e-testing/10-10-SUMMARY.md`
</output>
