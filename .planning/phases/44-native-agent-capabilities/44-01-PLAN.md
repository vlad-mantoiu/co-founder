---
phase: 44-native-agent-capabilities
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - backend/app/agent/tools/definitions.py
  - backend/app/agent/tools/dispatcher.py
  - backend/app/agent/tools/e2b_dispatcher.py
  - backend/app/agent/loop/system_prompt.py
  - backend/tests/agent/test_narrate_tool.py
  - backend/tests/agent/test_document_tool.py
autonomous: true
requirements: [AGNT-04, AGNT-05]

must_haves:
  truths:
    - "narrate() tool dispatched by InMemoryToolDispatcher emits SSE event and writes to Redis log stream"
    - "narrate() tool dispatched by E2BToolDispatcher emits SSE event and writes to Redis log stream"
    - "document() tool dispatched writes to job:{id}:docs Redis hash and emits DOCUMENTATION_UPDATED SSE"
    - "document() rejects invalid section names with error string"
    - "narrate() and document() tool schemas appear in AGENT_TOOLS list"
    - "System prompt instructs agent to call narrate() tool instead of inline text narration"
  artifacts:
    - path: "backend/tests/agent/test_narrate_tool.py"
      provides: "Unit tests for narrate() tool dispatch"
      min_lines: 60
    - path: "backend/tests/agent/test_document_tool.py"
      provides: "Unit tests for document() tool dispatch"
      min_lines: 60
    - path: "backend/app/agent/tools/definitions.py"
      provides: "narrate and document tool schemas in AGENT_TOOLS"
      contains: "narrate"
    - path: "backend/app/agent/tools/dispatcher.py"
      provides: "InMemoryToolDispatcher with narrate/document handlers"
      contains: "_narrate"
    - path: "backend/app/agent/tools/e2b_dispatcher.py"
      provides: "E2BToolDispatcher with narrate/document handlers"
      contains: "_narrate"
    - path: "backend/app/agent/loop/system_prompt.py"
      provides: "Updated narration instruction using narrate() tool"
      contains: "narrate()"
  key_links:
    - from: "backend/app/agent/tools/dispatcher.py"
      to: "app.queue.state_machine.SSEEventType"
      via: "import in _narrate/_document handlers"
      pattern: "SSEEventType\\.BUILD_STAGE_STARTED"
    - from: "backend/app/agent/tools/dispatcher.py"
      to: "Redis job:{id}:docs hash"
      via: "self._redis.hset in _document"
      pattern: "hset.*job:.*:docs"
    - from: "backend/app/agent/tools/e2b_dispatcher.py"
      to: "app.queue.state_machine.SSEEventType"
      via: "import in _narrate/_document handlers"
      pattern: "SSEEventType\\.BUILD_STAGE_STARTED"
---

<objective>
Add narrate() and document() tools to the agent's tool dispatch system via TDD, and update the system prompt to instruct the agent to use narrate() instead of inline text narration.

Purpose: The agent must be able to narrate its work in first-person co-founder voice (AGNT-04) and generate end-user documentation progressively (AGNT-05) as native tool calls within the TAOR loop, replacing the external NarrationService and DocGenerationService.

Output: Two new tool schemas in AGENT_TOOLS, handler methods in both InMemoryToolDispatcher and E2BToolDispatcher, updated system prompt, and comprehensive tests.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/44-native-agent-capabilities/44-RESEARCH.md
@backend/app/agent/tools/definitions.py
@backend/app/agent/tools/dispatcher.py
@backend/app/agent/tools/e2b_dispatcher.py
@backend/app/agent/loop/system_prompt.py
@backend/app/queue/state_machine.py
@backend/app/services/log_streamer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RED — Write failing tests for narrate() and document() tools</name>
  <files>
    backend/tests/agent/test_narrate_tool.py
    backend/tests/agent/test_document_tool.py
  </files>
  <action>
Create two test files covering all behaviors of the new tools.

**backend/tests/agent/test_narrate_tool.py:**
All tests use `@pytest.mark.unit` and `@pytest.mark.asyncio`.

1. `test_narrate_tool_in_agent_tools` — import AGENT_TOOLS from definitions.py, assert a tool with name="narrate" exists, assert it has input_schema with required=["message"].

2. `test_narrate_emits_sse_event` — construct InMemoryToolDispatcher with `job_id="test-narrate-001"`, `redis=fakeredis.aioredis.FakeRedis(decode_responses=True)`, `state_machine=MagicMock(publish_event=AsyncMock(return_value=None))`. Call `dispatcher.dispatch("narrate", {"message": "I'm setting up auth with Clerk."})`. Assert:
   - Result is `"[narration emitted]"`
   - `state_machine.publish_event` called once
   - Call args: first arg is job_id `"test-narrate-001"`, second arg dict has `"type"` equal to `SSEEventType.BUILD_STAGE_STARTED`, `"narration"` equal to the message, `"stage"` equal to `"agent"`, `"agent_role"` equal to `"Engineer"`

3. `test_narrate_writes_to_redis_stream` — same dispatcher setup as above. Call dispatch. Assert Redis stream `job:test-narrate-001:logs` has at least 1 entry (use `redis.xlen()`).

4. `test_narrate_empty_message_ignored` — dispatch with `{"message": ""}`. Assert result is `"[narrate: empty message ignored]"`. Assert `state_machine.publish_event` NOT called.

5. `test_narrate_without_redis_returns_stub` — construct InMemoryToolDispatcher with `job_id="test"` but `redis=None`, `state_machine=None`. Dispatch narrate. Assert result is `"[narration emitted]"` (no crash — graceful degradation).

6. `test_narrate_e2b_dispatcher_emits_sse` — construct E2BToolDispatcher with `runtime=MagicMock()`, plus `job_id="test-e2b-001"`, `redis=fakeredis.aioredis.FakeRedis(decode_responses=True)`, `state_machine=MagicMock(publish_event=AsyncMock())`. Call `dispatcher.dispatch("narrate", {"message": "Building auth."})`. Assert SSE emitted and result is `"[narration emitted]"`.

**backend/tests/agent/test_document_tool.py:**
All tests use `@pytest.mark.unit` and `@pytest.mark.asyncio`.

1. `test_document_tool_in_agent_tools` — assert tool with name="document" exists in AGENT_TOOLS, has input_schema with required=["section", "content"], section has enum with 4 values.

2. `test_document_writes_to_redis_hash` — construct InMemoryToolDispatcher with `job_id="test-doc-001"`, `redis=fakeredis.aioredis.FakeRedis(decode_responses=True)`, `state_machine=MagicMock(publish_event=AsyncMock())`. Call `dispatcher.dispatch("document", {"section": "overview", "content": "This app lets you..."})`. Assert:
   - Result contains `"[doc section 'overview' written"`
   - `await redis.hget("job:test-doc-001:docs", "overview")` returns `"This app lets you..."`

3. `test_document_emits_documentation_updated_sse` — same setup. Call dispatch. Assert `state_machine.publish_event` called with payload containing `"type"` = `SSEEventType.DOCUMENTATION_UPDATED` and `"section"` = `"overview"`.

4. `test_document_invalid_section` — dispatch with `{"section": "changelog", "content": "..."}`. Assert result contains `"invalid section"`. Assert `state_machine.publish_event` NOT called.

5. `test_document_empty_content_ignored` — dispatch with `{"section": "overview", "content": "  "}`. Assert result contains `"empty content"`. Assert `state_machine.publish_event` NOT called.

6. `test_document_all_four_sections` — dispatch each of overview, features, getting_started, faq. Assert all 4 keys exist in Redis hash `job:{id}:docs`.

7. `test_document_without_redis_returns_stub` — construct with `redis=None`, `state_machine=None`. Dispatch. Assert returns a doc section written message (no crash).

8. `test_document_e2b_dispatcher_writes_hash` — construct E2BToolDispatcher with `runtime=MagicMock()`, plus `job_id`, `redis`, `state_machine`. Call dispatch document. Assert Redis hash written.

Tests should import SSEEventType from `app.queue.state_machine` for assertion comparisons.

Run: `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/test_narrate_tool.py tests/agent/test_document_tool.py -x -q`
Expect: ALL tests FAIL (ImportError or AttributeError — handlers don't exist yet).
  </action>
  <verify>
    <automated>cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/test_narrate_tool.py tests/agent/test_document_tool.py -x -q 2>&1 | tail -5</automated>
    <manual>Tests exist and fail for the right reason (missing implementation, not syntax errors)</manual>
    <sampling_rate>run after this task commits, before next task begins</sampling_rate>
  </verify>
  <done>Both test files exist with 14 total test functions. All tests fail because narrate/document handlers and tool schemas don't exist yet.</done>
</task>

<task type="auto">
  <name>Task 2: GREEN — Implement narrate() and document() tools + update system prompt</name>
  <files>
    backend/app/agent/tools/definitions.py
    backend/app/agent/tools/dispatcher.py
    backend/app/agent/tools/e2b_dispatcher.py
    backend/app/agent/loop/system_prompt.py
  </files>
  <action>
**1. Add tool schemas to `definitions.py`:**

Append two new tool dicts to the AGENT_TOOLS list:

narrate tool:
```python
{
    "name": "narrate",
    "description": (
        "Narrate a significant action in first-person co-founder voice. "
        "Call this when you start or complete a major step — authentication setup, "
        "database schema design, API routing, feature completion, etc. "
        "Include WHAT you are doing AND WHY, referencing the founder's brief when relevant. "
        "Skip minor actions like individual file writes or grep calls. "
        "Example: 'I\\'m setting up auth with Clerk because your brief specified enterprise-grade security.'"
    ),
    "input_schema": {
        "type": "object",
        "properties": {
            "message": {
                "type": "string",
                "description": "First-person narration of the significant action being taken.",
            },
        },
        "required": ["message"],
    },
}
```

document tool:
```python
{
    "name": "document",
    "description": (
        "Write a section of end-user documentation for the product being built. "
        "Call this progressively as you complete major features — document auth after setting it up, "
        "document onboarding after building it. "
        "Sections: 'overview', 'features', 'getting_started', 'faq'. "
        "Write for the product's end users, not the founder. Plain English, no technical jargon, "
        "no file paths, no framework names. Use 'you' and 'your' throughout."
    ),
    "input_schema": {
        "type": "object",
        "properties": {
            "section": {
                "type": "string",
                "enum": ["overview", "features", "getting_started", "faq"],
                "description": "Documentation section to write.",
            },
            "content": {
                "type": "string",
                "description": "Markdown content for the section.",
            },
        },
        "required": ["section", "content"],
    },
}
```

**2. Update `InMemoryToolDispatcher` in `dispatcher.py`:**

Add constructor parameters (all optional, backward compatible):
```python
def __init__(
    self,
    failure_map: dict[tuple[str, int], Exception] | None = None,
    job_id: str = "",
    redis=None,
    state_machine=None,
) -> None:
```
Store them as `self._job_id`, `self._redis`, `self._state_machine`.

Add routing in `dispatch()` method — BEFORE the unknown-tool fallback:
```python
if tool_name == "narrate":
    return await self._narrate(tool_input)
if tool_name == "document":
    return await self._document(tool_input)
```

Add `_narrate()` method:
- Extract `message` from tool_input. If empty, return `"[narrate: empty message ignored]"`.
- If `self._state_machine` and `self._job_id`, call `await self._state_machine.publish_event(self._job_id, {"type": SSEEventType.BUILD_STAGE_STARTED, "stage": "agent", "narration": message, "agent_role": "Engineer", "time_estimate": ""})`. Import SSEEventType from `app.queue.state_machine` inside the method (avoid circular at module level).
- If `self._redis` and `self._job_id`, write to Redis stream. Use `await self._redis.xadd(f"job:{self._job_id}:logs", {"data": json.dumps({"text": message, "source": "agent", "phase": "agent"})})` — import json at top of file. This matches the LogStreamer's stream key format without instantiating LogStreamer (simpler for the in-memory dispatcher).
- Return `"[narration emitted]"`.

Add `_document()` method:
- Extract `section` and `content` from tool_input.
- Validate section in `["overview", "features", "getting_started", "faq"]`. If invalid, return error string.
- If content is empty/whitespace, return error string.
- If `self._redis` and `self._job_id`, `await self._redis.hset(f"job:{self._job_id}:docs", section, content)`.
- If `self._state_machine` and `self._job_id`, publish SSE with `SSEEventType.DOCUMENTATION_UPDATED` and `"section": section`.
- Return `f"[doc section '{section}' written ({len(content)} chars)]"`.

**3. Update `E2BToolDispatcher` in `e2b_dispatcher.py`:**

Add constructor parameters for `job_id` (already exists!), `redis`, and `state_machine`:
```python
def __init__(
    self,
    runtime: "E2BSandboxRuntime",
    screenshot_service: "ScreenshotService | None" = None,
    project_id: str | None = None,
    job_id: str | None = None,
    preview_url: str | None = None,
    redis=None,
    state_machine=None,
) -> None:
```
Store as `self._redis` and `self._state_machine`.

Add routing in `dispatch()` method before the unknown-tool fallback:
```python
if tool_name == "narrate":
    return await self._narrate(tool_input)
if tool_name == "document":
    return await self._document(tool_input)
```

Add `_narrate()` and `_document()` methods — identical logic to InMemoryToolDispatcher's versions. Both are thin wrappers: emit SSE + write Redis. Copy the same implementation. Use `self._job_id` (already stored).

**4. Update `_PERSONA_SECTION` in `system_prompt.py`:**

Replace the old narration instructions block:
```
**Narration (mandatory):**
- Narrate before every tool call: "I'm creating the auth module..." or "Let's scaffold the project structure."
- Narrate after every tool call: "Auth module created. Moving to routes."
- Narrate reasoning alongside actions — share WHY decisions are made.
- After each major group of work, provide a section summary: e.g. "Authentication complete: created login/register endpoints, JWT middleware, and user model. Moving to routes."
- Use distinct labeled phases in the narration stream so the founder sees named stages.
```

With the new instructions:
```
**Narration (mandatory):**
- Call narrate() at significant steps: phase starts, major architectural decisions,
  feature completions. ~1 narrate() call per major step, not per file write.
- Include WHAT you are doing AND WHY. Reference the founder's brief when it adds value.
  Example: "I'm setting up auth with Clerk because your brief specified enterprise-grade security."
- Do NOT narrate in plain text — use the narrate() tool so narration reaches the activity feed.

**Documentation (progressive):**
- Call document() as you complete major features — document auth after building it, not at the end.
- Write for the product's end users. Plain English, "you/your", no technical jargon.
- Use sections: overview, features, getting_started, faq.
```

Keep ALL other parts of `_PERSONA_SECTION` unchanged (Identity, Voice, Formatting, Guardrails sections).

Run tests: `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/test_narrate_tool.py tests/agent/test_document_tool.py -x -q`
Then run full agent suite: `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/ -x -q`
  </action>
  <verify>
    <automated>cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/test_narrate_tool.py tests/agent/test_document_tool.py tests/agent/test_tool_dispatcher.py tests/agent/test_e2b_dispatcher.py -x -q</automated>
    <manual>Verify narrate and document tool schemas appear in AGENT_TOOLS; system prompt references narrate() tool</manual>
    <sampling_rate>run after this task commits, before next task begins</sampling_rate>
  </verify>
  <done>All narrate/document tests pass. Existing tool_dispatcher and e2b_dispatcher tests still pass (backward compatible — new constructor params are optional). System prompt tells agent to call narrate() tool.</done>
</task>

</tasks>

<verification>
1. `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/test_narrate_tool.py tests/agent/test_document_tool.py -x -v` — all 14 tests pass
2. `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/ -x -q` — all existing agent tests still pass (no regressions)
3. `python -c "from app.agent.tools.definitions import AGENT_TOOLS; names = [t['name'] for t in AGENT_TOOLS]; assert 'narrate' in names; assert 'document' in names; print('OK')"` — confirms tool schemas registered
4. `grep -c "narrate()" backend/app/agent/loop/system_prompt.py` — returns >= 1 (system prompt updated)
</verification>

<success_criteria>
- AGENT_TOOLS contains 9 tools (7 original + narrate + document)
- InMemoryToolDispatcher.dispatch("narrate", ...) emits SSE via state_machine.publish_event()
- InMemoryToolDispatcher.dispatch("document", ...) writes to Redis hash job:{id}:docs
- E2BToolDispatcher.dispatch("narrate", ...) and dispatch("document", ...) work identically
- System prompt instructs narrate() tool usage, not inline text narration
- All existing agent tests pass without modification (backward compatible)
</success_criteria>

<output>
After completion, create `.planning/phases/44-native-agent-capabilities/44-01-SUMMARY.md`
</output>
