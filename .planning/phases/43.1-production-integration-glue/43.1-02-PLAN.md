---
phase: 43.1-production-integration-glue
plan: "02"
type: execute
wave: 2
depends_on: ["43.1-01"]
files_modified:
  - backend/app/agent/runner_autonomous.py
  - backend/tests/services/test_generation_service_autonomous.py
  - backend/tests/e2e/test_autonomous_build_e2e.py
autonomous: true
requirements: [MIGR-04, AGNT-01, AGNT-02, AGNT-03]

must_haves:
  truths:
    - "S3SnapshotService.sync() is called before agent sleeps (budget exhaustion)"
    - "S3SnapshotService.sync() is called on checkpoint saves (phase-commit boundary approximation)"
    - "Unit tests verify execute_build() calls run_agent_loop() with correct context keys"
    - "Unit tests verify E2BToolDispatcher is injected as context['dispatcher']"
    - "Unit tests verify idea_brief and understanding_qna are read from DB and present in context"
    - "E2E test covers start build -> TAOR loop runs -> tools dispatch -> cost tracked -> checkpoint saved"
    - "The 501 gate no longer blocks autonomous builds in any test"
  artifacts:
    - path: "backend/app/agent/runner_autonomous.py"
      provides: "S3 snapshot sync at sleep boundary and on checkpoint"
      contains: "snapshot_service"
    - path: "backend/tests/services/test_generation_service_autonomous.py"
      provides: "Unit integration tests for autonomous execute_build branch"
      min_lines: 80
    - path: "backend/tests/e2e/test_autonomous_build_e2e.py"
      provides: "E2E integration test with mocked E2B + mocked Anthropic"
      min_lines: 50
  key_links:
    - from: "backend/app/agent/runner_autonomous.py"
      to: "backend/app/agent/sync/s3_snapshot.py"
      via: "snapshot_service.sync() at sleep boundary"
      pattern: "snapshot_service.*sync"
    - from: "backend/tests/services/test_generation_service_autonomous.py"
      to: "backend/app/services/generation_service.py"
      via: "Tests verify autonomous branch wiring"
      pattern: "run_agent_loop"
    - from: "backend/tests/e2e/test_autonomous_build_e2e.py"
      to: "backend/app/services/generation_service.py"
      via: "E2E test exercises full pipeline"
      pattern: "execute_build"
---

<objective>
Add S3 snapshot sync hooks to the TAOR loop (at sleep boundary and checkpoint saves), then write comprehensive unit tests for the autonomous execute_build() branch and a full E2E integration test covering the build -> TAOR -> tools -> budget -> checkpoint pipeline.

Purpose: The autonomous branch wired in Plan 01 needs snapshot durability hooks (MIGR-04) and test coverage to verify all integration points work together. Without tests, any regression in service injection or context assembly would go undetected until production.

Output: Modified runner_autonomous.py with snapshot hooks, new test files covering all requirements.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/43.1-production-integration-glue/43.1-RESEARCH.md
@.planning/phases/43.1-production-integration-glue/43.1-01-SUMMARY.md
@backend/app/agent/runner_autonomous.py
@backend/app/services/generation_service.py
@backend/app/agent/sync/s3_snapshot.py
@backend/tests/agent/test_taor_budget_integration.py
@backend/tests/services/test_generation_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add S3 snapshot sync hooks to runner_autonomous.py</name>
  <files>
    backend/app/agent/runner_autonomous.py
  </files>
  <action>
    Add S3 snapshot sync calls to the TAOR loop in `run_agent_loop()` at two points per locked decisions:

    **1. Before agent sleeps (forced sync regardless of phase status):**

    In the sleep/wake transition block (Integration Point 4 from Phase 43-04), BEFORE `await wake_daemon.wake_event.wait()`, add:

    ```python
    # Forced S3 sync before sleep — prevent work loss during long sleep periods (MIGR-04)
    snapshot_service = context.get("snapshot_service")
    sandbox_runtime = context.get("sandbox_runtime")
    if snapshot_service and sandbox_runtime:
        try:
            await snapshot_service.sync(
                runtime=sandbox_runtime,
                project_id=context.get("project_id", ""),
            )
        except Exception:
            logger.warning("pre_sleep_snapshot_failed", session_id=session_id, exc_info=True)
    ```

    **2. At checkpoint save boundaries (phase-commit boundary approximation):**

    In Integration Point 3 (after checkpoint_service.save()), add a snapshot sync call. This approximates "phase commit boundaries" by syncing after each TAOR iteration's checkpoint is saved:

    ```python
    # S3 snapshot at checkpoint boundary — approximates phase commit (MIGR-04)
    # Per locked decision: batch at boundaries, not per write_file/edit_file
    snapshot_service = context.get("snapshot_service")
    sandbox_runtime = context.get("sandbox_runtime")
    if snapshot_service and sandbox_runtime:
        try:
            await snapshot_service.sync(
                runtime=sandbox_runtime,
                project_id=context.get("project_id", ""),
            )
        except Exception:
            logger.warning("checkpoint_snapshot_failed", session_id=session_id, exc_info=True)
    ```

    **IMPORTANT:** Both sync calls are wrapped in try/except with logger.warning — S3 failures must NEVER block the agent (non-fatal, per S3SnapshotService design). The `snapshot_service` and `sandbox_runtime` are both optional context keys — the code must check their presence before calling.

    **3. Extract snapshot_service and sandbox_runtime from context at session start:**

    At the top of `run_agent_loop()` where other context keys are extracted, add:
    ```python
    snapshot_service = context.get("snapshot_service")
    sandbox_runtime = context.get("sandbox_runtime")
    ```

    Then use these local variables at both sync points instead of re-reading from context each time.
  </action>
  <verify>
    <automated>cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/test_taor_loop.py tests/agent/test_taor_budget_integration.py -x -q --tb=short</automated>
    <manual>grep -c "snapshot_service" backend/app/agent/runner_autonomous.py should show 4+ occurrences</manual>
  </verify>
  <done>
    - snapshot_service.sync() called before wake_event.wait() in sleep transition
    - snapshot_service.sync() called after checkpoint_service.save() on each iteration
    - Both calls are non-fatal (try/except with logger.warning)
    - Both calls are conditional on snapshot_service and sandbox_runtime being present in context
    - All existing TAOR and budget integration tests still pass (no regressions)
  </done>
</task>

<task type="auto">
  <name>Task 2: Write unit integration tests and E2E test for autonomous build pipeline</name>
  <files>
    backend/tests/services/test_generation_service_autonomous.py
    backend/tests/e2e/__init__.py
    backend/tests/e2e/test_autonomous_build_e2e.py
  </files>
  <action>
    **1. Create backend/tests/services/test_generation_service_autonomous.py:**

    Write unit-level integration tests that verify each service injection point in the autonomous `execute_build()` branch. Use the established patterns from `test_taor_budget_integration.py` and `test_generation_service.py`.

    All tests should mock: E2B sandbox (AsyncMock), Anthropic API (MockStream pattern from test_taor_budget_integration.py), DB session (mock queries returning test artifacts), Redis (AsyncMock), and services (BudgetService, CheckpointService, WakeDaemon as AsyncMock).

    **Required tests (minimum 6):**

    - `test_autonomous_calls_run_agent_loop`: When `autonomous_agent=True`, `execute_build()` calls `runner.run_agent_loop(context)` and NOT `runner.run()`. Mock the runner and assert `run_agent_loop` was called.

    - `test_context_contains_db_artifacts`: The context dict passed to `run_agent_loop()` contains `idea_brief` (dict from Artifact table) and `understanding_qna` (list[dict] with question/answer keys normalized from UnderstandingSession). Mock DB queries to return test records, capture the context arg from `run_agent_loop.call_args`.

    - `test_e2b_dispatcher_injected`: The context dict contains a `dispatcher` key whose value is an instance of `E2BToolDispatcher` (not `InMemoryToolDispatcher`). Verify via `isinstance()` on the captured context.

    - `test_budget_checkpoint_wake_injected`: The context dict contains `budget_service`, `checkpoint_service`, and `wake_daemon` keys with correct types (not None when Redis is available).

    - `test_model_resolved_from_tier`: `resolve_llm_config()` is called with the correct `user_id` and `role="coder"`. The resolved model is set on `runner._model` before `run_agent_loop()` executes. Mock `resolve_llm_config` to return `"claude-opus-4-20250514"` and verify.

    - `test_wake_daemon_launched_as_task`: `asyncio.create_task()` is called with `wake_daemon.run()`. Patch `asyncio.create_task` and verify it was called with the daemon's run coroutine.

    - `test_s3_snapshot_on_completion`: After `run_agent_loop()` returns, `snapshot_service.sync()` is called with the sandbox runtime and project_id. Mock snapshot_service and verify call.

    **Mocking pattern for GenerationService:**
    ```python
    from unittest.mock import AsyncMock, MagicMock, patch

    # Mock runner
    runner = AsyncMock(spec=AutonomousRunner)
    runner.run_agent_loop.return_value = {"status": "completed", "project_id": "test"}
    runner._model = "claude-sonnet-4-20250514"

    # Mock sandbox factory
    mock_sandbox = AsyncMock()
    mock_sandbox.sandbox_id = "sbx-test"
    mock_sandbox._preview_url = "https://preview.e2b.dev"
    sandbox_factory = MagicMock(return_value=mock_sandbox)

    service = GenerationService(runner=runner, sandbox_runtime_factory=sandbox_factory)

    # Mock DB queries via patch on get_session_factory
    # Mock settings with autonomous_agent=True
    ```

    **2. Create backend/tests/e2e/__init__.py (empty package marker)**

    **3. Create backend/tests/e2e/test_autonomous_build_e2e.py:**

    Write a single E2E integration test that exercises the full pipeline with mocked external services. Per locked decisions: mock E2B sandbox + mock Anthropic API, skip sleep/wake cycle.

    **E2E test `test_e2e_autonomous_build_pipeline`:**

    - Set up: Mock E2B sandbox (start succeeds, run_command returns exit_code=0), mock Anthropic stream returning one `end_turn` response after one tool call, mock Redis, mock DB with idea_brief artifact and understanding session.
    - Execute: Call `service.execute_build(job_id, job_data, state_machine, redis)` with `autonomous_agent=True`.
    - Assert:
      1. `runner.run_agent_loop()` was called (not `runner.run()`)
      2. Context dict has `dispatcher` (E2BToolDispatcher type)
      3. Context dict has `idea_brief` and `understanding_qna`
      4. Result contains `sandbox_id`, `preview_url`, `build_version`
      5. State machine transitioned through STARTING -> SCAFFOLD -> CODE stages

    **Per locked decision:** Skip sleep/wake cycle assertions — already covered by Phase 43 unit tests.

    **4. Search and update any existing tests that assert 501:**
    - Run `grep -rn "501" backend/tests/` and update any test that expects a 501 response from the generation endpoint. Change those assertions to expect the new behavior (build proceeds normally or returns the configured error for `AUTONOMOUS_AGENT=False`).
  </action>
  <verify>
    <automated>cd /Users/vladcortex/co-founder/backend && python -m pytest tests/services/test_generation_service_autonomous.py tests/e2e/test_autonomous_build_e2e.py -x -v --tb=short 2>&1 | tail -30</automated>
    <manual>Verify test count: at least 7 unit tests + 1 E2E test passing</manual>
    <sampling_rate>run after this task commits, before verifying full suite</sampling_rate>
  </verify>
  <done>
    - tests/services/test_generation_service_autonomous.py has 7+ passing tests
    - tests/e2e/test_autonomous_build_e2e.py has 1+ passing E2E test
    - Tests verify: run_agent_loop called, context has DB artifacts, E2BToolDispatcher injected, budget/checkpoint/wake injected, model resolved, wake daemon launched, S3 snapshot synced
    - E2E test verifies: full pipeline with mocked externals, state transitions, result dict
    - No test in the suite asserts a 501 response
    - Full test suite passes: `python -m pytest tests/ -x -q --tb=short`
  </done>
</task>

</tasks>

<verification>
1. `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/agent/test_taor_loop.py tests/agent/test_taor_budget_integration.py -x -q` — existing tests pass (no regressions from snapshot hooks)
2. `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/services/test_generation_service_autonomous.py -x -v` — 7+ new tests pass
3. `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/e2e/test_autonomous_build_e2e.py -x -v` — E2E test passes
4. `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/ -x -q --tb=short` — full suite green
5. `grep -c "snapshot_service" backend/app/agent/runner_autonomous.py` — 4+ occurrences
6. `grep -rn "501" backend/tests/ | grep -i generation` — no matches (gate tests updated)
</verification>

<success_criteria>
- S3SnapshotService.sync() called at sleep boundary and checkpoint boundary in runner_autonomous.py
- 7+ unit tests verify all autonomous branch integration points
- 1 E2E test verifies the full build pipeline end-to-end
- All 161+ existing tests still pass
- No test in the entire suite asserts a 501 response from the generation endpoint
</success_criteria>

<output>
After completion, create `.planning/phases/43.1-production-integration-glue/43.1-02-SUMMARY.md`
</output>
