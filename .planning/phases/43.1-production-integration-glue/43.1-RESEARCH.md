# Phase 43.1: Production Integration Glue - Research

**Researched:** 2026-02-27
**Domain:** FastAPI service wiring, asyncio task management, SQLAlchemy async queries, pytest mocking patterns
**Confidence:** HIGH

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions

**GenerationService rewrite scope:**
- Modify `execute_build()` inline with an if-branch when `AUTONOMOUS_AGENT=True` — do not create a separate method
- Context dict assembled inline inside `execute_build()` — no factory or builder pattern
- `execute_build()` queries Artifact records from DB for `idea_brief` and `understanding_qna` using `project_id` — self-contained, not passed from caller
- Old `RunnerReal.run()` path: Claude's discretion on whether to keep or remove based on whether it has remaining value

**501 gate removal:**
- Remove the 501 gate entirely — no readiness check replacement
- Keep `AUTONOMOUS_AGENT` env var as a kill switch — when False, build endpoint returns an appropriate error (Claude's discretion on HTTP status)
- `WakeDaemon.run()` launched as `asyncio.create_task` per-build alongside the TAOR loop — lifecycle tied to the build, not a global singleton

**S3 snapshot sync timing:**
- Batch S3 sync at GSD phase commit boundaries — not per write_file/edit_file call
- Forced S3 sync before agent sleeps (budget exhaustion) regardless of phase status
- Full tar of project each sync — no incremental diffing. `S3SnapshotService` already supports this
- Rolling retention of last 5 snapshots per build — older snapshots deleted

**E2E test approach:**
- Mock E2B sandbox + mock Anthropic API — fast, deterministic, runs in CI without API keys
- Minimum E2E scenario: start build → TAOR loop runs 1 iteration → tool dispatches → cost tracked → checkpoint saved
- Skip sleep/wake cycle in E2E — already covered by Phase 43 unit tests
- Write separate unit-level integration tests for each service injection (BudgetService wired, CheckpointService wired, etc.) in addition to the single E2E test

### Claude's Discretion
- HTTP status code when `AUTONOMOUS_AGENT=False` (503 vs 501 vs other)
- Whether old `RunnerReal.run()` path is kept or removed
- Exact error message/response when agent is disabled
- Model resolution implementation details (resolve_llm_config call site)

### Deferred Ideas (OUT OF SCOPE)
None — discussion stayed within phase scope.
</user_constraints>

## Summary

Phase 43.1 is pure integration glue: all constituent services exist and are individually tested (161 tests passing). The task is to wire them into `GenerationService.execute_build()` so that when `AUTONOMOUS_AGENT=True`, the method assembles a fully-populated context dict and calls `runner.run_agent_loop()` instead of `runner.run()`. The 501 gate currently blocking all builds is removed, unlocking the end-to-end path.

The key research findings are: (1) `AutonomousRunner.run_agent_loop()` already accepts all required context keys — `idea_brief`, `understanding_qna`, `dispatcher`, `budget_service`, `checkpoint_service`, `wake_daemon`, `db_session`, `redis`, `tier`, `session_id`, `state_machine`; (2) DB queries for `idea_brief` and `understanding_qna` follow an established pattern already used in `gate_service.py` and `understanding_service.py`; (3) `resolve_llm_config()` already exists in `llm_config.py` and resolves model from subscription tier; (4) `E2BToolDispatcher` is already fully implemented and satisfies the `ToolDispatcher` protocol; (5) S3 snapshot calls must be inserted at graceful-sleep and phase-commit points within the TAOR loop flow, specifically in `execute_build()` wrapping logic or via a post-dispatch hook pattern.

**Primary recommendation:** Wire `execute_build()` with an `if settings.autonomous_agent:` branch that queries DB artifacts, instantiates all services, and delegates to `runner.run_agent_loop()`. Remove the 501 gate. Add `resolve_llm_config()` call to set the model on `AutonomousRunner` construction. The E2E test reuses the existing `MockStream` + mocked dispatcher pattern from `test_taor_budget_integration.py`.

<phase_requirements>
## Phase Requirements

| ID | Description | Research Support |
|----|-------------|-----------------|
| MIGR-04 | E2B sandbox file sync to S3 after each commit step — mitigates multi-resume file loss (E2B #884) | `S3SnapshotService.sync()` exists at `backend/app/agent/sync/s3_snapshot.py`. Needs to be called from `execute_build()` at phase-commit boundaries and before agent sleep. |
| AGNT-01 | Agent executes TAOR loop using Anthropic tool-use API | `AutonomousRunner.run_agent_loop()` is fully implemented. `execute_build()` currently calls `runner.run()` (old path) — must switch to `run_agent_loop()` when `AUTONOMOUS_AGENT=True`. |
| AGNT-02 | Agent consumes Understanding Interview QnA + Idea Brief as input context | `idea_brief` lives in `Artifact` table (`artifact_type="idea_brief"`). `understanding_qna` lives in `UnderstandingSession` table (`questions` + `answers` columns). Both require async DB queries from `project_id`. |
| AGNT-03 | Agent has 7 Claude Code-style tools operating inside E2B sandbox | `E2BToolDispatcher` is complete at `backend/app/agent/tools/e2b_dispatcher.py`. Must be injected as `context["dispatcher"]` replacing `InMemoryToolDispatcher`. |
</phase_requirements>

---

## Standard Stack

### Core (no new dependencies — all existing)

| Component | Location | Purpose | Status |
|-----------|----------|---------|--------|
| `AutonomousRunner` | `app/agent/runner_autonomous.py` | TAOR loop execution | Complete — needs to be called from `execute_build()` |
| `E2BToolDispatcher` | `app/agent/tools/e2b_dispatcher.py` | E2B sandbox tool dispatch | Complete — needs injection via `context["dispatcher"]` |
| `S3SnapshotService` | `app/agent/sync/s3_snapshot.py` | Snapshot project to S3 | Complete — needs call site in `execute_build()` |
| `BudgetService` | `app/agent/budget/service.py` | Token budget tracking | Complete — needs injection via `context["budget_service"]` |
| `CheckpointService` | `app/agent/budget/checkpoint.py` | Message history persistence | Complete — needs injection via `context["checkpoint_service"]` |
| `WakeDaemon` | `app/agent/budget/wake_daemon.py` | Sleep/wake lifecycle | Complete — needs `asyncio.create_task(daemon.run())` |
| `resolve_llm_config()` | `app/core/llm_config.py` | Model resolution from subscription tier | Complete — needs call in `execute_build()` before runner init |
| `GenerationService` | `app/services/generation_service.py` | Build pipeline orchestration | NEEDS MODIFICATION — add autonomous branch |
| `start_generation` endpoint | `app/api/routes/generation.py` | Build start route | NEEDS MODIFICATION — remove 501 gate |

### Supporting (read patterns from existing services)

| Pattern | Location | Purpose |
|---------|----------|---------|
| Artifact query by type | `app/services/gate_service.py` lines 92, 296 | Query `Artifact` by `artifact_type="idea_brief"` |
| UnderstandingSession query | `app/services/gate_service.py` lines 311-315 | Query latest QnA session for project |
| `get_session_factory()` | `app/db/base.py` | Open async DB session inside `execute_build()` |
| `asyncio.to_thread(boto3.*)` | `app/agent/sync/s3_snapshot.py` | Blocked boto3 calls — project pattern |

---

## Architecture Patterns

### Pattern 1: execute_build() Autonomous Branch

The existing `execute_build()` calls `runner.run(agent_state)` at the CODE stage. The autonomous branch replaces this call when `AUTONOMOUS_AGENT=True`.

**Current code (lines 141-166 of generation_service.py):**
```python
# 3. CODE — run the Runner pipeline
await state_machine.transition(job_id, JobStatus.CODE, "Running LLM code generation pipeline")
...
final_state = await self.runner.run(agent_state)
```

**New pattern — inline if-branch:**
```python
# 3. CODE — run the Runner pipeline
await state_machine.transition(job_id, JobStatus.CODE, "Running LLM code generation pipeline")
streamer._phase = "code"
await streamer.write_event("--- Running autonomous agent ---")

if _settings.autonomous_agent:
    # Assemble context for autonomous TAOR loop
    context = await _build_agent_context(
        job_id=job_id,
        job_data=job_data,
        sandbox=sandbox,
        state_machine=state_machine,
        redis=_redis,
        db_session=db_session,   # opened once before this block
    )
    # Launch WakeDaemon as background task (per-build, not global singleton)
    wake_daemon = context["wake_daemon"]
    asyncio.create_task(wake_daemon.run())
    # Run TAOR loop
    agent_result = await self.runner.run_agent_loop(context)
    # Handle result...
else:
    final_state = await self.runner.run(agent_state)
    # ... existing path ...
```

**Note:** The `sandbox` is created BEFORE the if-branch (E2B sandbox must exist before `E2BToolDispatcher` can be instantiated). The existing pipeline creates sandbox at step 4 (DEPS). For autonomous builds, sandbox creation moves to before the TAOR call. Alternatively, sandbox is still created first and injected into dispatcher.

Actually re-reading the success criteria: the context dict contains `idea_brief` and `understanding_qna` read from DB. The sandbox is not in the context dict — `E2BToolDispatcher` is injected as `context["dispatcher"]` and the dispatcher wraps the sandbox runtime. Therefore the sequence is:

```
1. STARTING transition
2. SCAFFOLD transition (query DB artifacts + build context dict)
3. Start E2B sandbox
4. Instantiate E2BToolDispatcher(runtime=sandbox)
5. CODE transition → run_agent_loop(context with dispatcher injected)
6. CHECKS transition (if needed for autonomous path — TBD)
7. READY (worker handles)
```

### Pattern 2: DB Artifact Queries in execute_build()

The `execute_build()` method does not currently open a DB session. For the autonomous branch, it needs one to read `idea_brief` and `understanding_qna`. Use `get_session_factory()` with async context manager — same pattern as `_get_next_build_version()`.

```python
# Query idea_brief Artifact record
from app.db.base import get_session_factory
from app.db.models.artifact import Artifact
from sqlalchemy import select
import uuid

factory = get_session_factory()
async with factory() as db_session:
    # idea_brief
    result = await db_session.execute(
        select(Artifact).where(
            Artifact.project_id == uuid.UUID(project_id),
            Artifact.artifact_type == "idea_brief",
        )
    )
    idea_brief_record = result.scalar_one_or_none()
    idea_brief = idea_brief_record.current_content or {} if idea_brief_record else {}

    # understanding_qna — from UnderstandingSession (latest)
    from app.db.models.understanding_session import UnderstandingSession
    session_result = await db_session.execute(
        select(UnderstandingSession)
        .where(UnderstandingSession.project_id == uuid.UUID(project_id))
        .order_by(UnderstandingSession.created_at.desc())
        .limit(1)
    )
    u_session = session_result.scalar_one_or_none()
    understanding_qna = []
    if u_session and u_session.questions and u_session.answers:
        for q in u_session.questions:
            qid = q.get("id", "")
            answer = u_session.answers.get(qid, "")
            if answer:
                understanding_qna.append({"question": q.get("text", ""), "answer": answer})
```

**CRITICAL:** The `UnderstandingSession` stores questions as a list of dicts and answers as `{question_id: answer_text}`. The `build_system_prompt()` function expects `understanding_qna: list[dict]` where each dict has `"question"` and `"answer"` keys (see `system_prompt.py` lines 84-86: `for entry in understanding_qna: ... entry.get("question") ... entry.get("answer")`). The query must normalize the QnA into this format.

### Pattern 3: resolve_llm_config() for Model Resolution (BDGT-05)

`AutonomousRunner.__init__()` currently takes `model` as a constructor parameter with a hardcoded default of `"claude-sonnet-4-20250514"`. To resolve model from subscription tier, call `resolve_llm_config(user_id, role="coder")` before constructing the runner.

```python
from app.core.llm_config import resolve_llm_config

# In execute_build(), autonomous branch setup:
model = await resolve_llm_config(user_id, role="coder")
# AutonomousRunner is already constructed before execute_build() (via _build_runner())
# Claude's discretion: either reconstruct with correct model here,
# or set self._model on the existing instance, or thread model through context
```

**Important:** `_build_runner()` in `generation.py` constructs `AutonomousRunner()` with no args (uses default model). The model resolution must happen at build time, not at runner construction time. Options:
1. Set `runner._model = model` inside `execute_build()` before calling `run_agent_loop()`
2. Pass model via `context["model"]` and have `run_agent_loop()` read it (requires adding this key support)
3. Move runner construction inside `execute_build()` and construct with resolved model

Option 1 (set `runner._model` before loop) is simplest and avoids changing `_build_runner()` or `run_agent_loop()` signature. This is the recommended approach.

### Pattern 4: S3 Snapshot Injection Points

Per locked decisions, S3 sync fires at:
1. **GSD phase commit boundaries** — this means after the agent signals a phase is done (likely detected from tool output pattern in the TAOR loop or at specific checkpoints)
2. **Before agent sleeps** (forced sync regardless of phase status)

The current `E2BToolDispatcher` does NOT call `S3SnapshotService.sync()`. The locked decision says sync at "GSD phase commit boundaries" not per write_file/edit_file call.

The cleanest implementation: `S3SnapshotService` is instantiated in `execute_build()` and injected via `context["snapshot_service"]`. The `AutonomousRunner` is then responsible for calling it at appropriate points (after recognizing a phase commit signal in tool output, or on sleep transition).

**Alternative (simpler):** Wrap `execute_build()` to call `S3SnapshotService.sync()` after `run_agent_loop()` returns (at natural completion) AND inside the sleep/wake transition in `runner_autonomous.py`. The `runner_autonomous.py` already has the sleep/wake code — inject `context["snapshot_service"]` and call `await snapshot_service.sync(runtime, project_id)` before `wake_daemon.wake_event.wait()`.

The `runtime` (E2BSandboxRuntime) is NOT currently in the context dict — it's managed by `execute_build()`. To pass it through for snapshot calls, add `context["sandbox_runtime"]` to the context.

**Recommended approach:** Inject both `context["snapshot_service"]` and `context["sandbox_runtime"]` into the context dict. Call `S3SnapshotService.sync()` at the forced-sleep boundary in `runner_autonomous.py` (already has the sleep transition block). For phase-commit boundaries, this will require a hook pattern — Claude's discretion on exact mechanism, but a simple approach is to call sync on every checkpoint save (checkpoint save already happens after each TAOR iteration; sync can happen alongside it).

### Pattern 5: WakeDaemon Lifecycle as asyncio.create_task

Per locked decision: `WakeDaemon.run()` launched as `asyncio.create_task` per-build alongside the TAOR loop. The WakeDaemon already runs as a background polling coroutine that sets `wake_event` when a wake condition is met. The TAOR loop (already implemented in `runner_autonomous.py`) calls `await wake_daemon.wake_event.wait()` on sleep.

```python
# In execute_build() autonomous branch:
session_id = job_id  # or str(uuid4()) for new session
wake_daemon = WakeDaemon(session_id=session_id, redis=_redis)
asyncio.create_task(wake_daemon.run())
context["wake_daemon"] = wake_daemon
```

**Pitfall:** `asyncio.create_task()` requires a running event loop. FastAPI's BackgroundTask executor runs inside the event loop — this is safe. However, the daemon task will run indefinitely if the build completes normally (no sleep triggered). This is acceptable for the per-build lifecycle since the task will be garbage collected when the coroutine frame ends (daemon exits on first wake signal or midnight).

### Anti-Patterns to Avoid

- **Creating sandbox after TAOR call:** `E2BToolDispatcher` requires a live `E2BSandboxRuntime` — the sandbox must be started BEFORE the dispatcher is instantiated and BEFORE `run_agent_loop()` is called.
- **Opening DB session per-query:** Open one `async with factory() as db_session:` for all queries in `execute_build()` — don't open multiple sessions.
- **Hardcoding model:** `AutonomousRunner.__init__()` has a default model. `resolve_llm_config()` must be awaited inside the async `execute_build()` to get the tier-correct model.
- **Blocking on WakeDaemon without asyncio.create_task:** The daemon's `run()` method is a long-polling coroutine — it must be launched as a background task, not awaited directly.

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| S3 uploads | Custom boto3 loop | `S3SnapshotService.sync()` | Already handles tar creation, 3-retry, rolling retention |
| Budget tracking | Manual token counting | `BudgetService` + `record_call_cost()` | Already handles Redis INCRBY, model weights, circuit breaker |
| Message persistence | Custom DB upsert | `CheckpointService.save()` | Already handles query-then-update, non-fatal wrapping |
| Sleep/wake polling | Custom Redis poller | `WakeDaemon.run()` | Already handles Redis signal + midnight check |
| Model resolution | Tier lookup | `resolve_llm_config()` | Already handles admin override → plan default → global fallback |
| Tool dispatch to E2B | Custom sandbox calls | `E2BToolDispatcher` | Already handles all 7 tools, ANSI stripping, output capping |

---

## Common Pitfalls

### Pitfall 1: UnderstandingSession QnA Format Mismatch
**What goes wrong:** `build_system_prompt()` expects `list[dict]` with keys `"question"` and `"answer"`. `UnderstandingSession` stores `{question_id: answer_text}` answers dict and a `questions` list. Direct injection of `u_session.answers` fails.
**Why it happens:** The two data models use different shapes.
**How to avoid:** Normalize QnA pairs as shown in Pattern 2 above — iterate questions, look up each answer by `q.id`.
**Warning signs:** `KeyError: 'question'` or `KeyError: 'answer'` in `system_prompt.py` at runtime.

### Pitfall 2: Sandbox Not Started Before Dispatcher
**What goes wrong:** `E2BToolDispatcher` receives an `E2BSandboxRuntime` that hasn't had `start()` called — all tool calls fail.
**Why it happens:** The current `execute_build()` creates sandbox at step 4 (DEPS). For autonomous builds, sandbox creation must happen before the TAOR loop at step 2-3.
**How to avoid:** Move sandbox creation to SCAFFOLD stage for the autonomous branch, or restructure to create sandbox before `run_agent_loop()`.
**Warning signs:** `E2BSandboxError: sandbox not started` in tool dispatch.

### Pitfall 3: DB Session Scope Too Narrow
**What goes wrong:** Opening a DB session in one block and passing it to `run_agent_loop()` as `context["db_session"]`, then the session being closed before the loop uses it for checkpoint saves.
**Why it happens:** `async with factory() as session:` auto-closes the session at the end of the `with` block.
**How to avoid:** Either keep a long-lived session open for the duration of `execute_build()` (pass it through the entire autonomous branch), or let `BudgetService` and `CheckpointService` open their own sessions internally. Looking at `BudgetService.calc_daily_budget()` — it accepts `db: AsyncSession` as an argument, suggesting caller controls the session.
**Recommended:** Open one session at the start of the autonomous branch and keep it open via `async with factory() as db_session:` that wraps the entire TAOR loop call. This means the `run_agent_loop()` call must be INSIDE the `async with` block.
**Warning signs:** `sqlalchemy.exc.InvalidRequestError: Session is closed`.

### Pitfall 4: resolve_llm_config() Raises on Suspended User
**What goes wrong:** `resolve_llm_config()` raises `PermissionError` if the user is suspended. This must be caught and converted to an appropriate HTTP error before the build starts.
**Why it happens:** The function is designed to gate access — it can raise.
**How to avoid:** Wrap the `resolve_llm_config()` call in a try/except `PermissionError` at the start of the autonomous branch in `execute_build()`, and transition to `FAILED` status with appropriate message.
**Warning signs:** Unhandled `PermissionError` propagating to the worker exception handler.

### Pitfall 5: Missing S3 Bucket Config in Tests
**What goes wrong:** `S3SnapshotService` reads `settings.screenshots_bucket` — wait, actually it takes `bucket` in `__init__`. But `execute_build()` will need to pass the correct bucket name.
**Why it happens:** The S3 snapshot bucket for project files is different from the screenshots bucket. There is no `project_snapshot_bucket` in settings yet — check if it needs to be added or if the screenshots bucket is reused.
**How to avoid:** Check `app/core/config.py` for existing bucket settings. Add `project_snapshot_bucket` if absent.

### Pitfall 6: 501 Gate Removal — Integration Test Expectations
**What goes wrong:** Any existing integration test that asserts the 501 response will fail after removing the gate.
**Why it happens:** The gate was tested to verify it blocks builds.
**How to avoid:** Search for `501` in existing tests and update assertions before removing the gate.
**Warning signs:** `AssertionError: expected 501 got 201` or similar.

---

## Code Examples

### Verified Pattern: Artifact DB Query (from gate_service.py)

```python
# Source: backend/app/services/gate_service.py lines 92-97
result = await session.execute(
    select(Artifact).where(
        Artifact.project_id == project.id,
        Artifact.artifact_type == "idea_brief",
    )
)
idea_brief_artifact = result.scalar_one_or_none()
```

### Verified Pattern: UnderstandingSession Query (from gate_service.py)

```python
# Source: backend/app/services/gate_service.py lines 311-315
u_session_result = await session.execute(
    select(UnderstandingSession)
    .where(UnderstandingSession.project_id == project.id)
    .order_by(UnderstandingSession.created_at.desc())
    .limit(1)
)
u_session = u_session_result.scalar_one_or_none()
```

### Verified Pattern: Context Dict for run_agent_loop() (from test_taor_budget_integration.py)

```python
# Source: backend/tests/agent/test_taor_budget_integration.py lines 115-130
ctx = {
    "project_id": "proj-abc",
    "user_id": "user-abc",
    "job_id": "job-abc",
    "session_id": "sess-abc",
    "idea_brief": {"problem": "..."},
    "understanding_qna": [{"question": "Revenue?", "answer": "SaaS"}],
    "build_plan": {"steps": ["scaffold"]},
    "redis": redis_client,
    "max_tool_calls": 150,
    "tier": "bootstrapper",
    "dispatcher": e2b_dispatcher,        # E2BToolDispatcher in prod
    "budget_service": budget_service,
    "checkpoint_service": checkpoint_service,
    "db_session": db_session,
    "wake_daemon": wake_daemon,
    "state_machine": state_machine,
    "session_id": job_id,
    "snapshot_service": s3_snapshot_service,  # NEW for Phase 43.1
    "sandbox_runtime": sandbox,               # NEW for Phase 43.1
}
```

### Verified Pattern: WakeDaemon Task Launch

```python
# Source: backend/app/agent/budget/wake_daemon.py + STATE.md decision
from app.agent.budget.wake_daemon import WakeDaemon

wake_daemon = WakeDaemon(session_id=session_id, redis=_redis)
asyncio.create_task(wake_daemon.run())  # fire-and-forget, not awaited
context["wake_daemon"] = wake_daemon
```

### Verified Pattern: S3SnapshotService.sync() Call Site

```python
# Source: backend/app/agent/sync/s3_snapshot.py
from app.agent.sync.s3_snapshot import S3SnapshotService

snapshot_svc = S3SnapshotService(bucket=settings.project_snapshot_bucket)
# At sleep boundary (inside runner_autonomous.py graceful wind-down block):
await snapshot_svc.sync(runtime=sandbox, project_id=project_id)
```

### Verified Pattern: 501 Gate Location (to remove)

```python
# Source: backend/app/api/routes/generation.py lines 239-246
# REMOVE THIS ENTIRE BLOCK:
if _get_settings().autonomous_agent:
    raise HTTPException(
        status_code=501,
        detail="Autonomous agent coming soon. Your AI Co-Founder is being built.",
    )
```

### Verified Pattern: Model Resolution

```python
# Source: backend/app/core/llm_config.py lines 66-92
from app.core.llm_config import resolve_llm_config

# In execute_build() autonomous branch — before runner call:
try:
    model = await resolve_llm_config(user_id, role="coder")
except PermissionError as exc:
    raise HTTPException(status_code=403, detail=str(exc))

# Apply to runner (runner was already constructed by _build_runner()):
self.runner._model = model
```

---

## State of the Art

| Old Approach | Current Approach | Status |
|--------------|-----------------|--------|
| LangGraph pipeline | Direct Anthropic SDK TAOR loop | Phase 40-41 complete |
| `runner.run()` | `runner.run_agent_loop(context)` | Phase 41 complete — needs wiring in GenerationService |
| 501 gate blocking autonomous builds | Remove gate, live flag controls behavior | Phase 43.1 target |
| Hardcoded model in AutonomousRunner | `resolve_llm_config()` for tier-based model | Phase 43.1 target |
| InMemoryToolDispatcher (test stub) | E2BToolDispatcher (live sandbox) | Phase 42 complete — needs injection in execute_build() |

---

## Open Questions

1. **Project snapshot bucket config**
   - What we know: `S3SnapshotService.__init__()` takes `bucket: str`. Settings currently has `screenshots_bucket` and `log_archive_bucket`.
   - What's unclear: Is there a separate bucket for project snapshots, or reuse `log_archive_bucket`?
   - Recommendation: Add `project_snapshot_bucket: str = ""` to `app/core/config.py` Settings and configure it in ECS task definition. Check if this S3 bucket already exists in CDK infrastructure (cofounder-screenshots bucket exists; a project-snapshots bucket may need to be provisioned).

2. **Sandbox pipeline reordering for autonomous builds**
   - What we know: Current pipeline creates sandbox at DEPS (step 4). Autonomous TAOR loop needs the sandbox before the loop starts (at CODE, step 3), so the dispatcher can be injected.
   - What's unclear: Does the DEPS stage need to remain for backwards compat or can the autonomous branch fully replace steps 3-5?
   - Recommendation: For the autonomous branch, create sandbox at SCAFFOLD/CODE stage and skip the DEPS/CHECKS stages as defined in the old pipeline. The autonomous agent handles its own file I/O via tools — there is no `working_files` dict to write.

3. **Return value from run_agent_loop() vs execute_build() contract**
   - What we know: `execute_build()` is expected to return `{sandbox_id, preview_url, build_version, workspace_path, _sandbox_runtime}`. `run_agent_loop()` returns `{status, project_id, phases_completed, result}`.
   - What's unclear: For the autonomous path, what is `preview_url`? The agent uses `take_screenshot` which has a `preview_url` — this is the E2B preview URL from `sandbox.start_dev_server()`.
   - Recommendation: After `run_agent_loop()` completes, call `sandbox.start_dev_server()` (or read the preview URL if the agent's sandbox already started it) and construct the standard return dict. Alternatively, the TAOR loop itself starts the dev server via bash tools — in that case, `preview_url` is extracted from agent output or set to the sandbox's base preview URL.

---

## Validation Architecture

### Test Framework
| Property | Value |
|----------|-------|
| Framework | pytest 8.x + pytest-asyncio |
| Config file | `backend/pyproject.toml` (`[tool.pytest.ini_options]`) |
| Quick run command | `cd backend && python -m pytest tests/agent/ -x -q --tb=short` |
| Full suite command | `cd backend && python -m pytest tests/ -x -q --tb=short` |
| Estimated runtime | ~2 seconds (161 tests) |

### Phase Requirements → Test Map
| Req ID | Behavior | Test Type | Automated Command | File Exists? |
|--------|----------|-----------|-------------------|-------------|
| AGNT-01 | `execute_build()` calls `run_agent_loop()` when `AUTONOMOUS_AGENT=True` | unit | `pytest tests/services/test_generation_service_autonomous.py -x` | No — Wave 0 gap |
| AGNT-02 | Context dict contains `idea_brief` and `understanding_qna` from DB | unit | `pytest tests/services/test_generation_service_autonomous.py::test_context_contains_db_artifacts -x` | No — Wave 0 gap |
| AGNT-03 | `E2BToolDispatcher` injected as `context["dispatcher"]` | unit | `pytest tests/services/test_generation_service_autonomous.py::test_e2b_dispatcher_injected -x` | No — Wave 0 gap |
| MIGR-04 | `S3SnapshotService.sync()` called before agent sleep | unit | `pytest tests/services/test_generation_service_autonomous.py::test_s3_sync_before_sleep -x` | No — Wave 0 gap |
| All | E2E: start build → TAOR runs → tools dispatch → cost tracked → checkpoint saved | integration | `pytest tests/e2e/test_autonomous_build_e2e.py -x` | No — Wave 0 gap |
| 501 gate | `start_generation` returns non-501 when `AUTONOMOUS_AGENT=True` | unit | `pytest tests/api/test_generation_endpoint.py::test_no_501_gate -x` | No — Wave 0 gap |

### Nyquist Sampling Rate
- **Minimum sample interval:** After every committed task → run: `cd backend && python -m pytest tests/agent/ tests/services/ -x -q --tb=short`
- **Full suite trigger:** Before merging final task of any plan wave
- **Phase-complete gate:** Full suite green before `/gsd:verify-work` runs
- **Estimated feedback latency per task:** ~2-4 seconds

### Wave 0 Gaps (must be created before implementation)
- [ ] `tests/services/test_generation_service_autonomous.py` — covers AGNT-01, AGNT-02, AGNT-03, MIGR-04
- [ ] `tests/e2e/test_autonomous_build_e2e.py` — covers E2E integration scenario
- [ ] No new framework needed — pytest-asyncio already configured
- [ ] `tests/services/__init__.py` — if `tests/services/` directory doesn't exist

*(Check: `tests/services/` directory existence)*

---

## Sources

### Primary (HIGH confidence)
- Codebase direct inspection — `backend/app/services/generation_service.py` — full `execute_build()` implementation
- Codebase direct inspection — `backend/app/agent/runner_autonomous.py` — complete `run_agent_loop()` context interface
- Codebase direct inspection — `backend/app/api/routes/generation.py` lines 239-246 — exact 501 gate location
- Codebase direct inspection — `backend/app/core/llm_config.py` — `resolve_llm_config()` signature and behavior
- Codebase direct inspection — `backend/app/agent/tools/e2b_dispatcher.py` — `E2BToolDispatcher` constructor
- Codebase direct inspection — `backend/app/agent/sync/s3_snapshot.py` — `S3SnapshotService.sync()` interface
- Codebase direct inspection — `backend/app/services/gate_service.py` — established patterns for artifact + QnA DB queries
- Codebase direct inspection — `backend/app/db/models/understanding_session.py` — QnA data model shape
- Codebase direct inspection — `backend/tests/agent/test_taor_budget_integration.py` — established mock patterns for TAOR tests

### Secondary (MEDIUM confidence)
- `.planning/STATE.md` accumulated decisions — asyncio.create_task for WakeDaemon, S3 sync timing, DB session patterns

---

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH — all services exist and are tested; this is wiring only
- Architecture: HIGH — patterns established by existing test infrastructure and service code
- Pitfalls: HIGH — DB session scope, QnA format, and sandbox ordering are concrete code-level risks verified by inspection

**Research date:** 2026-02-27
**Valid until:** 2026-03-13 (2 weeks — stable codebase, no fast-moving dependencies)
