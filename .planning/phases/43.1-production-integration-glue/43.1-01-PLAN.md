---
phase: 43.1-production-integration-glue
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/core/config.py
  - backend/app/api/routes/generation.py
  - backend/app/services/generation_service.py
autonomous: true
requirements: [AGNT-01, AGNT-02, AGNT-03]

must_haves:
  truths:
    - "When AUTONOMOUS_AGENT=True, execute_build() calls runner.run_agent_loop(context) instead of runner.run(agent_state)"
    - "The context dict passed to run_agent_loop() contains idea_brief and understanding_qna read from the database"
    - "E2BToolDispatcher is injected as context['dispatcher'] with a live sandbox runtime"
    - "BudgetService, CheckpointService, and WakeDaemon are instantiated and injected into the context dict"
    - "WakeDaemon.run() is launched as asyncio.create_task alongside the TAOR loop"
    - "AutonomousRunner resolves model from subscription tier via resolve_llm_config()"
    - "The 501 gate in start_generation is removed"
    - "When AUTONOMOUS_AGENT=False, the build endpoint returns an error (not 501)"
  artifacts:
    - path: "backend/app/core/config.py"
      provides: "project_snapshot_bucket Settings field"
      contains: "project_snapshot_bucket"
    - path: "backend/app/api/routes/generation.py"
      provides: "501 gate removed, _build_runner updated"
    - path: "backend/app/services/generation_service.py"
      provides: "Autonomous branch in execute_build() with full service wiring"
      contains: "run_agent_loop"
  key_links:
    - from: "backend/app/services/generation_service.py"
      to: "backend/app/agent/runner_autonomous.py"
      via: "runner.run_agent_loop(context)"
      pattern: "run_agent_loop"
    - from: "backend/app/services/generation_service.py"
      to: "backend/app/agent/tools/e2b_dispatcher.py"
      via: "E2BToolDispatcher instantiation and injection as context['dispatcher']"
      pattern: "E2BToolDispatcher"
    - from: "backend/app/services/generation_service.py"
      to: "backend/app/core/llm_config.py"
      via: "resolve_llm_config() for tier-based model resolution"
      pattern: "resolve_llm_config"
    - from: "backend/app/services/generation_service.py"
      to: "backend/app/agent/budget/service.py"
      via: "BudgetService instantiation and injection"
      pattern: "BudgetService"
---

<objective>
Wire GenerationService.execute_build() to call run_agent_loop() with a fully-assembled context dict when AUTONOMOUS_AGENT=True, remove the 501 gate blocking autonomous builds, and resolve the model from the user's subscription tier.

Purpose: This is the critical integration point that connects all independently-built services (AutonomousRunner, E2BToolDispatcher, BudgetService, CheckpointService, WakeDaemon) into the production build pipeline. Without this wiring, the autonomous agent exists only as isolated, tested components that never execute together.

Output: Modified GenerationService with autonomous branch, 501 gate removed, model resolution wired, project_snapshot_bucket setting added.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/43.1-production-integration-glue/43.1-RESEARCH.md
@.planning/phases/43-token-budget-sleep-wake-daemon/43-04-SUMMARY.md
@.planning/phases/42-e2b-tool-dispatcher/42-01-SUMMARY.md
@.planning/phases/42-e2b-tool-dispatcher/42-02-SUMMARY.md
@.planning/phases/36-generationservice-wiring-api-routes/36-02-SUMMARY.md
@backend/app/services/generation_service.py
@backend/app/api/routes/generation.py
@backend/app/agent/runner_autonomous.py
@backend/app/core/config.py
@backend/app/core/llm_config.py
@backend/app/agent/tools/e2b_dispatcher.py
@backend/app/agent/sync/s3_snapshot.py
@backend/app/agent/budget/service.py
@backend/app/agent/budget/checkpoint.py
@backend/app/agent/budget/wake_daemon.py
@backend/app/db/models/artifact.py
@backend/app/db/models/understanding_session.py
@backend/app/services/gate_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Remove 501 gate, add project_snapshot_bucket setting, update _build_runner</name>
  <files>
    backend/app/core/config.py
    backend/app/api/routes/generation.py
  </files>
  <action>
    **1. Add project_snapshot_bucket to Settings (backend/app/core/config.py):**
    - Add `project_snapshot_bucket: str = ""` field to the Settings class, next to the existing `screenshots_bucket` and `log_archive_bucket` fields.
    - Add a comment: `# env: PROJECT_SNAPSHOT_BUCKET — S3 bucket for agent project file snapshots`

    **2. Remove 501 gate from start_generation (backend/app/api/routes/generation.py):**
    - Delete the entire block at lines ~239-246 that raises HTTPException(status_code=501) when `autonomous_agent` is True:
      ```python
      # Feature flag: autonomous agent not yet implemented — return 501 immediately
      from app.core.config import get_settings as _get_settings

      if _get_settings().autonomous_agent:
          raise HTTPException(
              status_code=501,
              detail="Autonomous agent coming soon. Your AI Co-Founder is being built.",
          )
      ```
    - When `AUTONOMOUS_AGENT=False`, update `_build_runner()` to NOT return `AutonomousRunner()`. Instead, when the flag is False AND no `anthropic_api_key` is configured, return `RunnerFake()`. When False AND key exists, return `RunnerReal()`. This is the existing behavior when autonomous_agent=False so no change needed in `_build_runner()`.
    - The net effect: the 501 gate is simply deleted. The rest of the endpoint proceeds normally — `_build_runner()` returns `AutonomousRunner()` when `autonomous_agent=True`, which is already the case. No additional logic needed.

    **3. Search for any existing tests that assert 501 status and update them:**
    - Run `grep -r "501" backend/tests/` to find any tests asserting the 501 response.
    - Update those tests: if `AUTONOMOUS_AGENT=True`, the endpoint should now return 200/201 (queued), not 501.
    - If tests mock the runner, ensure they work with `AutonomousRunner` in the autonomous path.
  </action>
  <verify>
    <automated>cd /Users/vladcortex/co-founder/backend && python -m pytest tests/ -x -q --tb=short -k "generation" 2>&1 | tail -20</automated>
    <manual>Verify 501 gate code is completely removed from generation.py</manual>
  </verify>
  <done>
    - The 501 HTTPException block is completely removed from start_generation
    - `project_snapshot_bucket` field exists in Settings
    - No test asserts a 501 response from the generation endpoint
    - All existing generation tests still pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire autonomous branch in execute_build() with full context assembly</name>
  <files>
    backend/app/services/generation_service.py
  </files>
  <action>
    Modify `execute_build()` in `GenerationService` to add an autonomous agent branch. Per locked decisions: inline if-branch, no factory, no separate method for context assembly.

    **1. Add imports at top of generation_service.py:**
    ```python
    from app.agent.tools.e2b_dispatcher import E2BToolDispatcher
    from app.agent.sync.s3_snapshot import S3SnapshotService
    from app.agent.budget.service import BudgetService
    from app.agent.budget.checkpoint import CheckpointService
    from app.agent.budget.wake_daemon import WakeDaemon
    from app.core.llm_config import resolve_llm_config
    from app.db.models.artifact import Artifact
    from app.db.models.understanding_session import UnderstandingSession
    ```

    **2. Inside execute_build(), after the SCAFFOLD stage (after the narration fire-and-forget), add the autonomous branch:**

    Replace the section starting at "# 3. CODE — run the Runner pipeline" through the end of "# 6. Compute build result fields" with a branching structure:

    ```python
    if _settings.autonomous_agent:
        # ---- AUTONOMOUS AGENT PATH ----
        # 2b. Query DB for idea_brief and understanding_qna (self-contained, not from caller)
        factory = get_session_factory()
        async with factory() as db_session:
            # Query idea_brief
            from sqlalchemy import select as _select
            idea_brief_result = await db_session.execute(
                _select(Artifact).where(
                    Artifact.project_id == uuid.UUID(project_id),
                    Artifact.artifact_type == "idea_brief",
                )
            )
            idea_brief_record = idea_brief_result.scalar_one_or_none()
            idea_brief = idea_brief_record.current_content or {} if idea_brief_record else {}

            # Query understanding_qna (latest session)
            u_session_result = await db_session.execute(
                _select(UnderstandingSession)
                .where(UnderstandingSession.project_id == uuid.UUID(project_id))
                .order_by(UnderstandingSession.created_at.desc())
                .limit(1)
            )
            u_session = u_session_result.scalar_one_or_none()
            understanding_qna = []
            if u_session and u_session.questions and u_session.answers:
                for q in u_session.questions:
                    qid = q.get("id", "")
                    answer = u_session.answers.get(qid, "")
                    if answer:
                        understanding_qna.append({"question": q.get("text", ""), "answer": answer})

            # 3. CODE — start sandbox and run autonomous TAOR loop
            await state_machine.transition(job_id, JobStatus.CODE, "Running autonomous agent")
            streamer._phase = "code"
            await streamer.write_event("--- Running autonomous agent ---")

            # Start E2B sandbox (must exist before E2BToolDispatcher)
            sandbox = self.sandbox_runtime_factory()
            await sandbox.start()
            await sandbox.set_timeout(3600)
            workspace_path = "/home/user/project"

            # Resolve model from subscription tier
            try:
                model = await resolve_llm_config(user_id, role="coder")
            except PermissionError as perm_exc:
                raise Exception(f"Build blocked: {perm_exc}") from perm_exc

            # Set model on runner (runner already constructed via _build_runner)
            self.runner._model = model

            # Instantiate services
            dispatcher = E2BToolDispatcher(
                runtime=sandbox,
                screenshot_service=_screenshot_service if _settings.screenshot_enabled else None,
                project_id=project_id,
                job_id=job_id,
                preview_url=None,  # Agent discovers preview URL via bash tools
            )

            snapshot_service = S3SnapshotService(
                bucket=_settings.project_snapshot_bucket,
            ) if _settings.project_snapshot_bucket else None

            budget_service = BudgetService(redis=_redis) if _redis else None
            checkpoint_service = CheckpointService() if _redis else None

            session_id = job_id
            wake_daemon = WakeDaemon(session_id=session_id, redis=_redis) if _redis else None

            # Assemble context dict (inline per locked decision)
            context = {
                "project_id": project_id,
                "user_id": user_id,
                "job_id": job_id,
                "session_id": session_id,
                "idea_brief": idea_brief,
                "understanding_qna": understanding_qna,
                "build_plan": {"goal": job_data.get("goal", "")},
                "redis": _redis,
                "max_tool_calls": 150,
                "tier": job_data.get("tier", "bootstrapper"),
                "dispatcher": dispatcher,
                "budget_service": budget_service,
                "checkpoint_service": checkpoint_service,
                "db_session": db_session,
                "wake_daemon": wake_daemon,
                "state_machine": state_machine,
                "snapshot_service": snapshot_service,
                "sandbox_runtime": sandbox,
            }

            # Launch WakeDaemon as background task (per-build, not global singleton)
            if wake_daemon:
                asyncio.create_task(wake_daemon.run())

            # Run TAOR loop
            agent_result = await self.runner.run_agent_loop(context)

            # Extract results
            sandbox_id = sandbox.sandbox_id
            preview_url = getattr(sandbox, "_preview_url", None) or ""
            build_version = await self._get_next_build_version(project_id, state_machine)

            # Post-build S3 snapshot (final sync at completion)
            if snapshot_service:
                try:
                    await snapshot_service.sync(runtime=sandbox, project_id=project_id)
                except Exception:
                    logger.warning("final_snapshot_sync_failed", job_id=job_id, exc_info=True)

        # 7. Post-build hook: MVP Built state transition (non-fatal)
        try:
            await self._handle_mvp_built_transition(
                job_id=job_id,
                project_id=project_id,
                build_version=build_version,
                preview_url=preview_url,
            )
        except Exception:
            logger.warning("mvp_built_hook_failed", job_id=job_id, exc_info=True)

        await emit_business_event("artifact_generated", user_id=user_id)

        return {
            "sandbox_id": sandbox_id,
            "preview_url": preview_url,
            "build_version": build_version,
            "workspace_path": workspace_path,
            "_sandbox_runtime": sandbox,
        }
    else:
        # ---- LEGACY RUNNER PATH (RunnerReal) ----
        # [Keep existing code from "3. CODE" through return statement]
    ```

    **CRITICAL IMPLEMENTATION NOTES:**

    1. The `async with factory() as db_session:` block MUST wrap the entire TAOR loop call because `db_session` is passed in the context dict and used by `BudgetService.calc_daily_budget()` and `CheckpointService.save()` during the loop. If the session closes before the loop completes, SQLAlchemy will raise `InvalidRequestError: Session is closed`.

    2. The `understanding_qna` normalization: `UnderstandingSession.questions` is `list[dict]` with `id` and `text` keys. `UnderstandingSession.answers` is `dict[str, str]` mapping `question_id` to `answer_text`. The `build_system_prompt()` in `system_prompt.py` expects `list[dict]` with `question` and `answer` keys. The normalization loop handles this format conversion.

    3. `sandbox` must be started BEFORE `E2BToolDispatcher` is instantiated — the dispatcher requires a live runtime.

    4. `resolve_llm_config()` can raise `PermissionError` for suspended users — catch it and convert to a build failure.

    5. The `select` import: `generation_service.py` already imports `select` from sqlalchemy at the top level. Use it directly (no need for `_select` alias). Adjust as needed if there's a naming conflict.

    6. The existing `else` branch preserves the full legacy code path (runner.run() with agent_state, sandbox creation, file writes, health check, dev server start).
  </action>
  <verify>
    <automated>cd /Users/vladcortex/co-founder/backend && python -c "from app.services.generation_service import GenerationService; print('Import OK')" && grep -c "run_agent_loop" app/services/generation_service.py</automated>
    <manual>Verify execute_build() has both autonomous and legacy branches</manual>
  </verify>
  <done>
    - execute_build() has an `if _settings.autonomous_agent:` branch that calls `runner.run_agent_loop(context)`
    - Context dict contains: idea_brief, understanding_qna (from DB), dispatcher (E2BToolDispatcher), budget_service, checkpoint_service, wake_daemon, db_session, redis, state_machine, snapshot_service, sandbox_runtime
    - DB session wraps the entire TAOR loop call (session stays open)
    - Model resolved via resolve_llm_config() before TAOR loop
    - WakeDaemon launched as asyncio.create_task
    - S3 snapshot sync called after TAOR loop completion
    - Legacy else branch preserves existing runner.run() path
    - Module imports cleanly without errors
  </done>
</task>

</tasks>

<verification>
1. `cd /Users/vladcortex/co-founder/backend && python -c "from app.services.generation_service import GenerationService; print('OK')"` — imports without error
2. `grep -c "run_agent_loop" backend/app/services/generation_service.py` — at least 1 occurrence
3. `grep -c "E2BToolDispatcher" backend/app/services/generation_service.py` — at least 1 occurrence
4. `grep "501" backend/app/api/routes/generation.py` — no matches (gate removed)
5. `grep "project_snapshot_bucket" backend/app/core/config.py` — at least 1 match
6. `cd /Users/vladcortex/co-founder/backend && python -m pytest tests/ -x -q --tb=short` — all existing tests pass
</verification>

<success_criteria>
- GenerationService.execute_build() calls runner.run_agent_loop(context) when AUTONOMOUS_AGENT=True
- Context dict is fully populated with all required services and DB-queried artifacts
- 501 gate is completely removed from generation.py
- project_snapshot_bucket setting exists in config.py
- All existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/43.1-production-integration-glue/43.1-01-SUMMARY.md`
</output>
