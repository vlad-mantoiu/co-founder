---
phase: 03-workspace-authentication
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/api/test_user_isolation.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "All 8 user isolation tests pass (previously 3/8)"
    - "Tests that create projects bypass subscription check without breaking isolation assertions"
    - "404-on-unauthorized pattern verified for get, delete, and link-github operations"
  artifacts:
    - path: "backend/tests/api/test_user_isolation.py"
      provides: "Complete user isolation test suite"
      contains: "mock_user_settings"
  key_links:
    - from: "test_user_isolation.py"
      to: "require_subscription"
      via: "mock get_or_create_user_settings returning trialing subscription"
      pattern: "get_or_create_user_settings.*mock_user_settings"
---

<objective>
Fix 5 failing user isolation integration tests by adding subscription status mocking.

Purpose: Close the only verification gap in Phase 03 — 5 tests fail with 403 because they create projects via POST /api/projects (which uses Depends(require_subscription)) but don't mock the subscription lookup. The user isolation implementation is correct; only the test mocking is incomplete.

Output: All 8/8 user isolation tests passing, verifying the 404-on-unauthorized pattern.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-workspace-authentication/03-03-SUMMARY.md
@.planning/phases/03-workspace-authentication/03-VERIFICATION.md

@backend/tests/api/test_user_isolation.py
@backend/tests/api/test_auth_middleware.py
@backend/tests/api/conftest.py
@backend/app/core/auth.py
@backend/app/api/routes/projects.py
@backend/app/core/llm_config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add subscription mocking to 5 failing user isolation tests</name>
  <files>backend/tests/api/test_user_isolation.py</files>
  <action>
The 5 failing tests all call POST /api/projects, which depends on `require_subscription`. That dependency queries UserSettings from the DB — but since provisioning is mocked (no actual DB row is created), the query finds no row and returns 403.

Two things need mocking for project creation to succeed:
1. `require_subscription` needs a UserSettings row with `stripe_subscription_status` in ("active", "trialing") — the dependency queries the DB directly via `select(UserSettings).where(...)`.
2. `create_project` calls `get_or_create_user_settings(user.user_id)` for plan limit checks — this also queries the DB.

The cleanest fix: Add `patch("app.core.llm_config.get_or_create_user_settings", mock_user_settings)` to the 5 failing tests, following the exact pattern already used in `test_owner_can_access_own_project`. The mock returns an object with `stripe_subscription_status = "trialing"`, `is_admin = False`, and plan tier attributes needed by the route.

However, `require_subscription` in auth.py does its OWN direct DB query — it does NOT call `get_or_create_user_settings`. So we also need to mock the DB query inside `require_subscription`. The simplest approach: use FastAPI's dependency_overrides to replace `require_subscription` with a passthrough that just returns the user from `require_auth`.

**Implementation approach — use `app.dependency_overrides` in conftest.py or directly in each test:**

Actually, since the test creates a fresh FastAPI app in `conftest.py`, the cleanest approach is to add a helper that patches `require_subscription` to bypass the DB query. But modifying conftest would affect other tests.

**Best approach per test:** For each of the 5 failing tests, add BOTH patches:

```python
# Mock for require_subscription (auth.py DB query)
# Since require_subscription queries UserSettings directly from DB,
# and no real UserSettings row exists (provisioning is mocked),
# we need to mock the DB session's execute result inside require_subscription.
# Simplest: patch the entire select query result.
```

Actually the simplest working approach: In each failing test's `with` block, add a patch on `app.core.auth.get_session_factory` that returns a mock session whose `execute` returns a mock UserSettings with `stripe_subscription_status = "trialing"` and `is_admin = False`. BUT this could interfere with the projects routes that also use `get_session_factory`.

**The truly simplest approach:** Since `require_subscription` is at module level in `app.core.auth`, and these tests already mock `app.core.auth.get_jwks_client` and `app.core.auth.get_settings`, we can mock `require_subscription` as a dependency. BUT the app is created in conftest.py and we don't have access to app.dependency_overrides easily from the test.

**Final approach — mock the DB layer in `require_subscription`:**

Create a module-level helper `_mock_user_settings_query()` that returns a mock async context manager for the session factory, where:
- `session.execute(select(UserSettings)...)` returns a result with `scalar_one_or_none()` returning a mock UserSettings with `stripe_subscription_status="trialing"`, `is_admin=False`
- Other `session.execute()` calls pass through to the real DB (for project creation queries)

This is too complex. The SIMPLEST working fix:

**Use `patch.object` on the `require_subscription` function to make it a passthrough.** Since `require_subscription` is imported directly in `projects.py` via `from app.core.auth import require_subscription`, we need to patch it where it's used:

For the 5 failing tests, add this patch to the `with` block:
```python
patch("app.api.routes.projects.require_subscription", side_effect=require_auth_passthrough)
```

Where `require_auth_passthrough` is a dependency that does the same as `require_auth` (already mocked in each test). Since `require_auth` is the first thing `require_subscription` calls anyway, we just need a function that returns the ClerkUser from the already-mocked `require_auth`.

**Concrete implementation:**

1. At the top of test_user_isolation.py, add import: `from app.core.auth import require_auth`

2. Add a helper function:
```python
async def _require_subscription_bypass(
    request: Request,
    credentials=Depends(_bearer_scheme),
) -> ClerkUser:
    """Bypass subscription check — delegates to require_auth only."""
    return await require_auth(request, credentials)
```

Actually this won't work because require_auth itself is being called with mocked dependencies.

**THE SIMPLEST CORRECT FIX:** Just add the `get_or_create_user_settings` mock that `test_owner_can_access_own_project` already uses. But we ALSO need to handle the `require_subscription` DB query. Looking at `require_subscription` more carefully:

```python
async def require_subscription(user: ClerkUser = Depends(require_auth)) -> ClerkUser:
    from app.db.base import get_session_factory
    from app.db.models.user_settings import UserSettings
    factory = get_session_factory()
    async with factory() as session:
        result = await session.execute(...)
        settings = result.scalar_one_or_none()
        ...
```

Since conftest.py initializes a REAL test database and seeds plan tiers, the DB is functional. The issue is that `provision_user_on_first_login` is MOCKED, so no UserSettings row exists in the DB. If we let provisioning run against the real test DB, it would create the row and `require_subscription` would find it.

**THE FIX:** Replace the mock provisioning with REAL provisioning. The test DB is initialized with `seed_plan_tiers()` (see conftest.py line 87), so provisioning can actually work. Remove the `mock_provision` patch from the 5 failing tests and let `provision_user_on_first_login` run for real against the test DB. This creates a UserSettings row with the default bootstrapper tier.

BUT: `provision_user_on_first_login` creates a UserSettings with `stripe_subscription_status` defaulting to None (not "trialing"), which would still fail the subscription check.

**THE ACTUAL SIMPLEST FIX:** Keep the provisioning mock, but ALSO mock `require_subscription` where it's imported. Since `projects.py` imports it as `from app.core.auth import require_subscription`, and the test app includes `api_router`, we can patch `app.api.routes.projects.require_subscription` to be a simple passthrough:

For all 5 failing tests, add this to the `with` block:
```python
patch("app.api.routes.projects.require_subscription", new=require_auth),
```

Wait — `require_auth` is an async function with specific FastAPI dependency injection signature. It IS a valid replacement since `require_subscription` depends on `require_auth` and just adds a subscription check. Replacing `require_subscription` with `require_auth` means the route just checks auth (which is already mocked) without checking subscription.

BUT: `create_project` also calls `get_or_create_user_settings(user.user_id)` at line 36 for the plan limit check. This will query the DB and fail. So we also need the `get_or_create_user_settings` mock.

**FINAL IMPLEMENTATION for each of the 5 failing tests:**

Add these two patches to each test's `with` block:
1. `patch("app.api.routes.projects.require_subscription", new=require_auth)` — bypasses subscription check, delegates to auth-only (already mocked)
2. `patch("app.core.llm_config.get_or_create_user_settings", mock_user_settings)` — returns mock UserSettings for plan limit check

Where `mock_user_settings` is an async function returning a Mock with:
- `stripe_subscription_status = "trialing"`
- `is_admin = False`
- `override_max_projects = None`
- `plan_tier.max_projects = 10`

Add the import `from app.core.auth import require_auth` at the top of the file.

Create a reusable `_mock_user_settings_for_projects` async helper at module level (after existing helpers) that returns a properly configured mock.

**The 5 tests to update:**
1. `test_owner_can_access_own_project` — already has `mock_user_settings` but missing the `require_subscription` bypass. It currently patches `get_or_create_user_settings` but that only handles the plan limit check, not the subscription dependency itself. Add the `require_subscription` patch.
2. `test_other_user_gets_404_on_foreign_project` — add both patches
3. `test_other_user_cannot_list_foreign_projects` — this test actually passes per verification, but its POST silently fails. Add both patches so the project is actually created and the test is meaningful.
4. `test_other_user_gets_404_on_delete` — add both patches
5. `test_other_user_gets_404_on_link_github` — add both patches
6. `test_404_response_does_not_leak_info` — add both patches

Do NOT modify the 2 tests that don't create projects:
- `test_admin_can_access_any_project` — no API calls, pure unit test
- `test_nonexistent_project_returns_404` — only does GET, no POST

For `test_other_user_cannot_list_foreign_projects`: Also add an assertion that the POST actually succeeded (`create_response.status_code == 200`) so the test is truly verifying that user_b cannot see user_a's project (not just that the project failed to create).

Important: Keep the `_make_token`, `_sign_jwt`, `_mock_jwks_client`, `_mock_settings` helpers unchanged — they work correctly for auth mocking.
  </action>
  <verify>
Run the full test suite:
```bash
cd /Users/vladcortex/co-founder && python -m pytest backend/tests/api/test_user_isolation.py -v
```
Expected: All 8 tests pass (previously 3/8).

Also run auth middleware tests to confirm no regressions:
```bash
cd /Users/vladcortex/co-founder && python -m pytest backend/tests/api/test_auth_middleware.py -v
```
Expected: All 7 tests still pass.
  </verify>
  <done>All 8/8 user isolation tests pass. The 5 previously-failing tests now properly mock subscription status, allowing project creation to succeed so the isolation pattern (404-on-unauthorized) is verified for all CRUD operations.</done>
</task>

</tasks>

<verification>
```bash
# Run all phase 03 tests
cd /Users/vladcortex/co-founder && python -m pytest backend/tests/api/test_user_isolation.py backend/tests/api/test_auth_middleware.py backend/tests/domain/test_provisioning.py backend/tests/domain/test_feature_flags.py -v

# Expected: All tests pass (8 isolation + 7 middleware + 5 provisioning + 6 feature flags = 26 total)
```
</verification>

<success_criteria>
- All 8 user isolation tests pass (was 3/8)
- All 7 auth middleware tests still pass (no regressions)
- POST /api/projects succeeds in tests with subscription mock
- 404-on-unauthorized pattern verified for: get project, delete project, link-github
- No info leakage: 404 for unauthorized identical to 404 for nonexistent
</success_criteria>

<output>
After completion, create `.planning/phases/03-workspace-authentication/03-04-SUMMARY.md`
</output>
