---
phase: 05-capacity-queue-worker-model
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - backend/app/queue/__init__.py
  - backend/app/queue/schemas.py
  - backend/app/queue/manager.py
  - backend/app/db/models/job.py
  - backend/app/db/models/__init__.py
  - backend/tests/domain/test_queue_schemas.py
  - backend/tests/domain/test_queue_manager.py
autonomous: true

must_haves:
  truths:
    - "Job enqueue creates entry in Redis sorted set with tier-based priority score"
    - "FIFO ordering preserved within same tier (lower counter = dequeued first)"
    - "CTO jobs jump ahead by 5 positions, Partner by 2, Bootstrapper by 0"
    - "Dequeue pops lowest-score job (highest priority + earliest enqueue)"
    - "Queue position is 1-indexed and accurate after concurrent enqueues"
    - "Global queue cap of 100 enforced — beyond 100 returns rejection with retry estimate"
  artifacts:
    - path: "backend/app/queue/schemas.py"
      provides: "JobRequest, JobStatus enum, JobRecord, UsageCounters Pydantic models"
      contains: "class JobStatus"
    - path: "backend/app/queue/manager.py"
      provides: "QueueManager with enqueue, dequeue, get_position, get_length"
      contains: "class QueueManager"
    - path: "backend/app/db/models/job.py"
      provides: "Job SQLAlchemy model for Postgres persistence"
      contains: "class Job"
  key_links:
    - from: "backend/app/queue/manager.py"
      to: "backend/app/queue/schemas.py"
      via: "imports JobStatus, JobRecord"
      pattern: "from app\\.queue\\.schemas import"
    - from: "backend/app/queue/manager.py"
      to: "redis"
      via: "Redis sorted set operations (ZADD, ZPOPMIN, ZRANK, ZCARD)"
      pattern: "redis\\.zadd|redis\\.zpopmin"
---

<objective>
Create the job queue foundation: Pydantic schemas for all queue-related types, the Job Postgres model for persistence, and the QueueManager class that implements Redis sorted set priority queuing with FIFO tiebreaker and tier-based boost.

Purpose: All other queue components depend on these foundational types and the core enqueue/dequeue mechanism. The priority queue is the heart of the capacity system.
Output: Working QueueManager with full TDD coverage, Job DB model, and shared schemas.
</objective>

<execution_context>
@/Users/vladcortex/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vladcortex/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-capacity-queue-worker-model/05-RESEARCH.md

Reference existing patterns:
@backend/app/db/models/project.py (SQLAlchemy model pattern)
@backend/app/db/models/__init__.py (model re-export pattern)
@backend/app/db/redis.py (Redis client access pattern: get_redis())
@backend/app/schemas/onboarding.py (Pydantic schema pattern)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create job queue schemas, Job DB model, and QueueManager with TDD</name>
  <files>
    backend/app/queue/__init__.py
    backend/app/queue/schemas.py
    backend/app/queue/manager.py
    backend/app/db/models/job.py
    backend/app/db/models/__init__.py
    backend/tests/domain/test_queue_schemas.py
    backend/tests/domain/test_queue_manager.py
  </files>
  <action>
    **RED phase first — write failing tests:**

    Create `backend/tests/domain/test_queue_schemas.py`:
    - Test JobStatus enum has all 9 states: queued, starting, scaffold, code, deps, checks, ready, failed, scheduled
    - Test JobRequest validates required fields (project_id, user_id, tier)
    - Test JobRecord includes all fields (job_id, project_id, user_id, tier, status, enqueued_at, position, score)
    - Test UsageCounters includes jobs_used, jobs_remaining, iterations_used, iterations_remaining, daily_limit_resets_at

    Create `backend/tests/domain/test_queue_manager.py`:
    - Use fakeredis (async) for Redis mock. Install fakeredis if not present: `pip install fakeredis[aioredis]`
    - Test enqueue returns position 1 for first job
    - Test enqueue with different tiers: CTO job enqueued after bootstrapper still gets lower position (priority boost)
    - Test FIFO within same tier: two bootstrapper jobs, first enqueued gets position 1
    - Test dequeue returns highest priority job (lowest score)
    - Test dequeue returns None on empty queue
    - Test get_position returns accurate 1-indexed position
    - Test global cap: enqueue 100 jobs, 101st raises/returns rejection
    - Test priority score calculation: base 1000, CTO boost -5 (score 995*1e12+counter), Partner -2 (998*1e12+counter), Bootstrapper +0 (1000*1e12+counter)

    **GREEN phase — implement:**

    Create `backend/app/queue/__init__.py` (empty module init).

    Create `backend/app/queue/schemas.py`:
    ```python
    class JobStatus(str, Enum):
        QUEUED = "queued"
        STARTING = "starting"
        SCAFFOLD = "scaffold"
        CODE = "code"
        DEPS = "deps"
        CHECKS = "checks"
        READY = "ready"
        FAILED = "failed"
        SCHEDULED = "scheduled"

    class JobRequest(BaseModel):
        project_id: str
        user_id: str
        tier: str  # bootstrapper, partner, cto_scale
        goal: str  # what to build

    class JobRecord(BaseModel):
        job_id: str
        project_id: str
        user_id: str
        tier: str
        status: JobStatus
        enqueued_at: str  # ISO 8601
        position: int
        score: float

    class UsageCounters(BaseModel):
        jobs_used: int
        jobs_remaining: int
        iterations_used: int
        iterations_remaining: int
        daily_limit_resets_at: str  # ISO 8601

    # Tier capacity constants (LOCKED decisions)
    TIER_CONCURRENT_USER = {"bootstrapper": 2, "partner": 3, "cto_scale": 10}
    TIER_CONCURRENT_PROJECT = {"bootstrapper": 2, "partner": 3, "cto_scale": 5}
    TIER_DAILY_LIMIT = {"bootstrapper": 5, "partner": 50, "cto_scale": 200}
    TIER_BOOST = {"cto_scale": 5, "partner": 2, "bootstrapper": 0}
    TIER_ITERATION_DEPTH = {"bootstrapper": 2, "partner": 3, "cto_scale": 5}
    GLOBAL_QUEUE_CAP = 100
    ```

    Create `backend/app/queue/manager.py`:
    ```python
    class QueueManager:
        QUEUE_KEY = "queue:pending"
        COUNTER_KEY = "queue:counter"

        def __init__(self, redis: Redis):
            self.redis = redis

        async def enqueue(self, job_id: str, tier: str) -> dict:
            # Check global cap (ZCARD)
            length = await self.redis.zcard(self.QUEUE_KEY)
            if length >= GLOBAL_QUEUE_CAP:
                return {"rejected": True, "message": "System busy", "retry_after_minutes": ...}

            # Atomic counter for FIFO
            counter = await self.redis.incr(self.COUNTER_KEY)

            # Composite score: (1000 - boost) * 1e12 + counter
            boost = TIER_BOOST.get(tier, 0)
            score = (1000 - boost) * 1e12 + counter

            await self.redis.zadd(self.QUEUE_KEY, {job_id: score})
            position = await self.get_position(job_id)

            return {"rejected": False, "position": position, "score": score}

        async def dequeue(self) -> str | None:
            result = await self.redis.zpopmin(self.QUEUE_KEY, count=1)
            if not result:
                return None
            job_id, _score = result[0]
            return job_id

        async def get_position(self, job_id: str) -> int:
            rank = await self.redis.zrank(self.QUEUE_KEY, job_id)
            return rank + 1 if rank is not None else 0

        async def get_length(self) -> int:
            return await self.redis.zcard(self.QUEUE_KEY)

        async def remove(self, job_id: str) -> None:
            await self.redis.zrem(self.QUEUE_KEY, job_id)
    ```

    Create `backend/app/db/models/job.py`:
    - UUID primary key (same pattern as Project model)
    - Fields: id, project_id (UUID FK to projects), clerk_user_id, tier, status, goal, enqueued_at, started_at, completed_at, error_message, debug_id, iterations_used, created_at, updated_at
    - Use lambda datetime defaults (project pattern)

    Update `backend/app/db/models/__init__.py`:
    - Add `from app.db.models.job import Job` and include in __all__
  </action>
  <verify>
    Run: `cd /Users/vladcortex/co-founder && python -m pytest backend/tests/domain/test_queue_schemas.py backend/tests/domain/test_queue_manager.py -v`
    All tests pass. Verify at least 8 test cases for manager, 4 for schemas.
  </verify>
  <done>
    JobStatus enum has 9 states. QueueManager enqueue/dequeue/position works with tier priority. FIFO within tier verified. Global cap of 100 enforced. Job model exists in Postgres. All tests green.
  </done>
</task>

</tasks>

<verification>
- `python -m pytest backend/tests/domain/test_queue_schemas.py -v` — all schema tests pass
- `python -m pytest backend/tests/domain/test_queue_manager.py -v` — all manager tests pass
- Verify JobStatus has exactly 9 values
- Verify TIER_BOOST constants match locked decisions: CTO=5, Partner=2, Bootstrapper=0
- Verify GLOBAL_QUEUE_CAP = 100
</verification>

<success_criteria>
- QueueManager.enqueue creates sorted set entry with composite score
- QueueManager.dequeue pops lowest score (highest priority)
- Tier boost: CTO+5, Partner+2, Bootstrapper+0 positions ahead
- Global cap 100 enforced with rejection message
- Job DB model matches project model patterns
- All tests green with fakeredis
</success_criteria>

<output>
After completion, create `.planning/phases/05-capacity-queue-worker-model/05-01-SUMMARY.md`
</output>
